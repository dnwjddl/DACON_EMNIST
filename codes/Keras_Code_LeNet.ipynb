{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\woojung\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\woojung\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\woojung\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\woojung\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\woojung\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\woojung\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\woojung\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\woojung\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\woojung\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\woojung\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\woojung\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\woojung\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#load data\n",
    "import data_import as data\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import seaborn as sns\n",
    "\n",
    "#training\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import (Conv2D, MaxPooling2D, Flatten, Dense, LeakyReLU, ReLU )\n",
    "\n",
    "\n",
    "#optimizer\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  1.14.0\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version: \",tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기\n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.getcwd()+'/data/train.csv')\n",
    "test  = pd.read_csv(os.getcwd()+'/data/test.csv')\n",
    "submission = pd.read_csv(os.getcwd()+'/data/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>digit</th>\n",
       "      <th>letter</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 787 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  digit letter  0  1  2  3  4  5  6  ...  774  775  776  777  778  779  \\\n",
       "0   1      5      L  1  1  1  4  3  0  0  ...    2    1    0    1    2    4   \n",
       "1   2      0      B  0  4  0  0  4  1  1  ...    0    3    0    1    4    1   \n",
       "2   3      4      L  1  1  2  2  1  1  1  ...    3    3    3    0    2    0   \n",
       "3   4      9      D  1  2  0  2  0  4  0  ...    3    3    2    0    1    4   \n",
       "4   5      6      A  3  0  2  4  0  3  0  ...    4    4    3    2    1    3   \n",
       "\n",
       "   780  781  782  783  \n",
       "0    4    4    3    4  \n",
       "1    4    2    1    2  \n",
       "2    3    0    2    2  \n",
       "3    0    0    1    1  \n",
       "4    4    3    1    2  \n",
       "\n",
       "[5 rows x 787 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048,)\n",
      "<class 'numpy.ndarray'>\n",
      "(2048,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x_data = train.iloc[:, 3:]\n",
    "y_data = train.iloc[:, 1]\n",
    "x_data = np.array(x_data / 255.)\n",
    "y_data = np.array(y_data)\n",
    "print(y_data.shape)\n",
    "print(type(x_data))\n",
    "print(y_data.shape)\n",
    "print(type(y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "img_rows, img_cols, img_ch = 28, 28, 1\n",
    "input_shape = (img_rows, img_cols, img_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 784)\n",
      "(1843, 28, 28, 1)\n",
      "(205, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_data.shape)\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_data, y_data, test_size = 0.1)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], *input_shape)\n",
    "x_val = x_val.reshape(x_val.shape[0], *input_shape)\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=10,  \n",
    "        zoom_range = 0.10,  \n",
    "        width_shift_range=0.1, \n",
    "        height_shift_range=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 생성\n",
    "---  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(Model):\n",
    "    def __init__(self, num_classes):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = Conv2D(6, kernel_size=(5,5), padding='same', activation='relu')\n",
    "        self.conv2 = Conv2D(16, kernel_size=(5,5), activation='relu')\n",
    "        self.max_pool = MaxPooling2D(pool_size=(2,2))\n",
    "        self.flatten = Flatten()\n",
    "        self.dense1 = Dense(120, activation='relu')\n",
    "        self.dense2 = Dense(84, activation='relu')\n",
    "        self.dense3 = Dense(num_classes, activation='softmax')\n",
    "    def call(self, x):\n",
    "        x = self.max_pool(self.conv1(x))\n",
    "        x = self.max_pool(self.conv2(x))\n",
    "        x = self.flatten(x)        \n",
    "        x = self.dense3(self.dense2(self.dense1(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adam = Adam(lr=5e-4)\n",
    "# COMPILE WITH ADAM OPTIMIZER AND CROSS ENTROPY COST\n",
    "model = LeNet5(num_classes)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method LeNet5.call of <__main__.LeNet5 object at 0x000002701D2D2288>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LeNet5.call of <__main__.LeNet5 object at 0x000002701D2D2288>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LeNet5.call of <__main__.LeNet5 object at 0x000002701D2D2288>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LeNet5.call of <__main__.LeNet5 object at 0x000002701D2D2288>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "Model: \"le_net5_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            multiple                  156       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            multiple                  2416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              multiple                  48120     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              multiple                  10164     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              multiple                  850       \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "_ = model.predict(x_val[:10])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a learning rate annealer\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                patience=3, \n",
    "                                verbose=1, \n",
    "                                factor=0.2, \n",
    "                                min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "            rotation_range=10, \n",
    "            width_shift_range=0.1, \n",
    "            height_shift_range=0.1, \n",
    "            zoom_range=0.1)\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=3, monitor='val_loss'),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='logs', histogram_freq=1, write_graph=True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "58/58 [==============================] - 1s 23ms/step - loss: 2.2917 - acc: 0.1210 - val_loss: 2.2354 - val_acc: 0.1610\n",
      "Epoch 2/80\n",
      "58/58 [==============================] - 1s 13ms/step - loss: 2.1789 - acc: 0.1975 - val_loss: 2.0199 - val_acc: 0.2488\n",
      "Epoch 3/80\n",
      "58/58 [==============================] - 1s 14ms/step - loss: 2.0665 - acc: 0.2447 - val_loss: 1.9101 - val_acc: 0.2829\n",
      "Epoch 4/80\n",
      "58/58 [==============================] - 1s 15ms/step - loss: 1.9510 - acc: 0.2827 - val_loss: 1.7470 - val_acc: 0.3805\n",
      "Epoch 5/80\n",
      "58/58 [==============================] - 1s 15ms/step - loss: 1.8620 - acc: 0.3397 - val_loss: 1.5452 - val_acc: 0.4878\n",
      "Epoch 6/80\n",
      "58/58 [==============================] - 1s 15ms/step - loss: 1.7595 - acc: 0.3787 - val_loss: 1.4346 - val_acc: 0.4829\n",
      "Epoch 7/80\n",
      "58/58 [==============================] - 1s 17ms/step - loss: 1.6721 - acc: 0.4118 - val_loss: 1.3645 - val_acc: 0.5073\n",
      "Epoch 8/80\n",
      "58/58 [==============================] - 1s 15ms/step - loss: 1.6026 - acc: 0.4335 - val_loss: 1.3935 - val_acc: 0.5073\n",
      "Epoch 9/80\n",
      "58/58 [==============================] - 1s 15ms/step - loss: 1.5891 - acc: 0.4281 - val_loss: 1.3766 - val_acc: 0.5024\n",
      "Epoch 10/80\n",
      "58/58 [==============================] - 1s 15ms/step - loss: 1.5134 - acc: 0.4721 - val_loss: 1.3040 - val_acc: 0.5561\n",
      "Epoch 11/80\n",
      "58/58 [==============================] - 1s 16ms/step - loss: 1.4553 - acc: 0.4921 - val_loss: 1.2091 - val_acc: 0.5659\n",
      "Epoch 12/80\n",
      "58/58 [==============================] - 1s 15ms/step - loss: 1.4458 - acc: 0.4829 - val_loss: 1.2465 - val_acc: 0.5512\n",
      "Epoch 13/80\n",
      "58/58 [==============================] - 1s 14ms/step - loss: 1.3780 - acc: 0.5247 - val_loss: 1.2613 - val_acc: 0.5854\n",
      "Epoch 14/80\n",
      "58/58 [==============================] - 1s 15ms/step - loss: 1.3833 - acc: 0.5100 - val_loss: 1.2499 - val_acc: 0.5707\n",
      "0 is done\n",
      "Epoch 1/80\n",
      "58/58 [==============================] - 1s 14ms/step - loss: 1.3201 - acc: 0.5431 - val_loss: 1.1487 - val_acc: 0.6146\n",
      "Epoch 2/80\n",
      "58/58 [==============================] - 1s 13ms/step - loss: 1.2637 - acc: 0.5600 - val_loss: 1.1982 - val_acc: 0.5951\n",
      "Epoch 3/80\n",
      "58/58 [==============================] - 1s 14ms/step - loss: 1.2836 - acc: 0.5524 - val_loss: 1.1506 - val_acc: 0.5707\n",
      "Epoch 4/80\n",
      "58/58 [==============================] - 1s 14ms/step - loss: 1.2140 - acc: 0.5681 - val_loss: 1.0366 - val_acc: 0.6585\n",
      "Epoch 5/80\n",
      "58/58 [==============================] - 1s 14ms/step - loss: 1.1866 - acc: 0.5849 - val_loss: 1.0412 - val_acc: 0.6634\n",
      "Epoch 6/80\n",
      "58/58 [==============================] - 1s 14ms/step - loss: 1.1828 - acc: 0.5952 - val_loss: 0.9621 - val_acc: 0.6878\n",
      "Epoch 7/80\n",
      "58/58 [==============================] - 1s 16ms/step - loss: 1.1345 - acc: 0.6023 - val_loss: 1.0340 - val_acc: 0.6537\n",
      "Epoch 8/80\n",
      "58/58 [==============================] - 1s 18ms/step - loss: 1.1579 - acc: 0.5947 - val_loss: 1.0860 - val_acc: 0.6390\n",
      "Epoch 9/80\n",
      "58/58 [==============================] - 1s 19ms/step - loss: 1.0852 - acc: 0.6158 - val_loss: 0.9386 - val_acc: 0.6976\n",
      "Epoch 10/80\n",
      "58/58 [==============================] - 1s 18ms/step - loss: 1.0869 - acc: 0.6256 - val_loss: 1.0465 - val_acc: 0.6683\n",
      "Epoch 11/80\n",
      "58/58 [==============================] - 1s 17ms/step - loss: 1.0652 - acc: 0.6305 - val_loss: 0.9362 - val_acc: 0.6732\n",
      "Epoch 12/80\n",
      "58/58 [==============================] - 1s 17ms/step - loss: 1.0275 - acc: 0.6457 - val_loss: 0.8777 - val_acc: 0.7122\n",
      "Epoch 13/80\n",
      "58/58 [==============================] - 1s 19ms/step - loss: 1.0596 - acc: 0.6316 - val_loss: 0.9117 - val_acc: 0.7268\n",
      "Epoch 14/80\n",
      "58/58 [==============================] - 1s 20ms/step - loss: 1.0037 - acc: 0.6424 - val_loss: 0.9342 - val_acc: 0.6976\n",
      "Epoch 15/80\n",
      "58/58 [==============================] - 1s 18ms/step - loss: 1.0275 - acc: 0.6375 - val_loss: 0.9601 - val_acc: 0.6732\n",
      "1 is done\n",
      "Epoch 1/80\n",
      "58/58 [==============================] - 1s 15ms/step - loss: 0.9895 - acc: 0.6636 - val_loss: 0.9310 - val_acc: 0.6829\n",
      "Epoch 2/80\n",
      "58/58 [==============================] - 1s 16ms/step - loss: 0.9419 - acc: 0.6658 - val_loss: 0.9528 - val_acc: 0.7073\n",
      "Epoch 3/80\n",
      "58/58 [==============================] - 1s 18ms/step - loss: 0.9680 - acc: 0.6674 - val_loss: 1.0144 - val_acc: 0.6732\n",
      "Epoch 4/80\n",
      "58/58 [==============================] - 1s 15ms/step - loss: 0.9451 - acc: 0.6766 - val_loss: 1.0059 - val_acc: 0.6683\n",
      "2 is done\n",
      "Epoch 1/80\n",
      "58/58 [==============================] - 1s 15ms/step - loss: 0.9159 - acc: 0.6848 - val_loss: 1.0370 - val_acc: 0.6537\n",
      "Epoch 2/80\n",
      "58/58 [==============================] - 1s 17ms/step - loss: 0.9109 - acc: 0.6717 - val_loss: 0.9120 - val_acc: 0.7415\n",
      "Epoch 3/80\n",
      "58/58 [==============================] - 1s 16ms/step - loss: 0.9150 - acc: 0.6777 - val_loss: 1.0843 - val_acc: 0.6537\n",
      "Epoch 4/80\n",
      "58/58 [==============================] - 1s 16ms/step - loss: 0.9130 - acc: 0.6717 - val_loss: 0.8869 - val_acc: 0.7268\n",
      "Epoch 5/80\n",
      "58/58 [==============================] - 1s 15ms/step - loss: 0.9055 - acc: 0.6923 - val_loss: 0.8687 - val_acc: 0.7171\n",
      "Epoch 6/80\n",
      "58/58 [==============================] - 1s 18ms/step - loss: 0.8438 - acc: 0.7113 - val_loss: 1.0218 - val_acc: 0.7122\n",
      "Epoch 7/80\n",
      "58/58 [==============================] - 1s 16ms/step - loss: 0.8538 - acc: 0.7059 - val_loss: 0.9610 - val_acc: 0.7073\n",
      "Epoch 8/80\n",
      "58/58 [==============================] - 1s 16ms/step - loss: 0.8221 - acc: 0.7162 - val_loss: 0.9025 - val_acc: 0.7268\n",
      "3 is done\n",
      "Epoch 1/80\n",
      "58/58 [==============================] - 1s 14ms/step - loss: 0.8187 - acc: 0.7211 - val_loss: 0.8989 - val_acc: 0.7317\n",
      "Epoch 2/80\n",
      "58/58 [==============================] - 1s 16ms/step - loss: 0.7986 - acc: 0.7341 - val_loss: 1.0136 - val_acc: 0.6927\n",
      "Epoch 3/80\n",
      "58/58 [==============================] - 1s 17ms/step - loss: 0.8141 - acc: 0.7195 - val_loss: 0.9463 - val_acc: 0.7171\n",
      "Epoch 4/80\n",
      "58/58 [==============================] - 1s 16ms/step - loss: 0.8241 - acc: 0.7146 - val_loss: 0.9062 - val_acc: 0.7171\n",
      "4 is done\n",
      "Epoch 1/80\n",
      "58/58 [==============================] - 1s 15ms/step - loss: 0.8287 - acc: 0.7130 - val_loss: 0.8728 - val_acc: 0.7268\n",
      "Epoch 2/80\n",
      "58/58 [==============================] - 1s 15ms/step - loss: 0.8067 - acc: 0.7233 - val_loss: 0.9316 - val_acc: 0.6976\n",
      "Epoch 3/80\n",
      "58/58 [==============================] - 1s 18ms/step - loss: 0.7934 - acc: 0.7244 - val_loss: 1.1864 - val_acc: 0.6146\n",
      "Epoch 4/80\n",
      "58/58 [==============================] - 1s 18ms/step - loss: 0.7667 - acc: 0.7287 - val_loss: 1.0531 - val_acc: 0.6927\n",
      "5 is done\n",
      "Epoch 1/80\n",
      "10/58 [====>.........................] - ETA: 0s - loss: 0.7895 - acc: 0.7469"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function TF_Output.<lambda> at 0x000002707EC27C18>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\woojung\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 1417, in <lambda>\n",
      "    __del__ = lambda self: None\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 1s 17ms/step - loss: 0.7748 - acc: 0.7303 - val_loss: 1.0362 - val_acc: 0.6780\n",
      "Epoch 2/80\n",
      "58/58 [==============================] - 1s 16ms/step - loss: 0.7717 - acc: 0.7379 - val_loss: 0.9450 - val_acc: 0.6878\n",
      "Epoch 3/80\n",
      "58/58 [==============================] - 1s 17ms/step - loss: 0.7413 - acc: 0.7254 - val_loss: 0.8877 - val_acc: 0.7171\n",
      "Epoch 4/80\n",
      "58/58 [==============================] - 1s 17ms/step - loss: 0.7097 - acc: 0.7509 - val_loss: 0.9909 - val_acc: 0.7122\n",
      "Epoch 5/80\n",
      "58/58 [==============================] - 1s 16ms/step - loss: 0.7646 - acc: 0.7450 - val_loss: 0.8993 - val_acc: 0.7122\n",
      "Epoch 6/80\n",
      "58/58 [==============================] - 1s 17ms/step - loss: 0.7203 - acc: 0.7564 - val_loss: 0.9897 - val_acc: 0.7024\n",
      "6 is done\n",
      "Epoch 1/80\n",
      "58/58 [==============================] - 1s 15ms/step - loss: 0.7269 - acc: 0.7330 - val_loss: 0.8817 - val_acc: 0.7415\n",
      "Epoch 2/80\n",
      "58/58 [==============================] - 1s 18ms/step - loss: 0.6925 - acc: 0.7564 - val_loss: 1.0500 - val_acc: 0.6780\n",
      "Epoch 3/80\n",
      "58/58 [==============================] - 1s 17ms/step - loss: 0.7076 - acc: 0.7461 - val_loss: 0.9526 - val_acc: 0.7122\n",
      "Epoch 4/80\n",
      "58/58 [==============================] - 1s 18ms/step - loss: 0.6727 - acc: 0.7667 - val_loss: 0.9788 - val_acc: 0.7122\n",
      "7 is done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-2ba72b7c5e62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=32), epochs=80,\n\u001b[1;32m----> 3\u001b[1;33m           validation_data=(x_val, y_val), verbose=1, callbacks = callbacks)\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{} is done\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1431\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1432\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1433\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m   1434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m       \u001b[0msamples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_samples_or_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m       \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Handle ProgBar as part of Callbacks once hooks are ready.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m       mode=mode)\n\u001b[0m\u001b[0;32m    179\u001b[0m   \u001b[1;31m# TODO(omalleyt): Handle ProgBar as part of Callbacks once hooks are ready.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m   \u001b[0mprogbar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mconfigure_callbacks\u001b[1;34m(callbacks, model, do_validation, batch_size, epochs, steps_per_epoch, samples, verbose, count_mode, mode)\u001b[0m\n\u001b[0;32m    103\u001b[0m   \u001b[1;31m# Set callback model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m   \u001b[0mcallback_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_callback_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m   \u001b[0mcallback_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m   set_callback_parameters(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mset_model\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m       \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks_v1.py\u001b[0m in \u001b[0;36mset_model\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m     \u001b[1;31m# histogram summaries only enabled in graph mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks_v1.py\u001b[0m in \u001b[0;36m_init_writer\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    171\u001b[0m           \u001b[0msummary_ops_v2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_graph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_summary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_summary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\summary\\writer\\writer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, logdir, graph, max_queue, flush_secs, graph_def, filename_suffix, session)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_closed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 370\u001b[1;33m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent_writer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\summary\\writer\\writer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, event_writer, graph, graph_def)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgraph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mgraph_def\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m       \u001b[1;31m# Calling it with both graph and graph_def for backward compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m       \u001b[1;31m# Also export the meta_graph_def in this case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m       \u001b[1;31m# graph may itself be a graph_def due to positional arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\summary\\writer\\writer.py\u001b[0m in \u001b[0;36madd_graph\u001b[1;34m(self, graph, global_step, graph_def)\u001b[0m\n\u001b[0;32m    212\u001b[0m                       \"or the deprecated `GraphDef`\")\n\u001b[0;32m    213\u001b[0m     \u001b[1;31m# Finally, add the graph_def to the summary writer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_graph_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue_graph_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_write_plugin_assets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\summary\\writer\\writer.py\u001b[0m in \u001b[0;36m_add_graph_def\u001b[1;34m(self, graph_def, global_step)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_add_graph_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m     \u001b[0mgraph_bytes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m     \u001b[0mevent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevent_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEvent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgraph_bytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36mSerializeToString\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1084\u001b[0m           'Message %s is missing required fields: %s' % (\n\u001b[0;32m   1085\u001b[0m           self.DESCRIPTOR.full_name, ','.join(self.FindInitializationErrors())))\n\u001b[1;32m-> 1086\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializePartialToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1087\u001b[0m   \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSerializeToString\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1088\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36mSerializePartialToString\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1093\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mSerializePartialToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1094\u001b[0m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1095\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_InternalSerialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1096\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1097\u001b[0m   \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializePartialToString\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSerializePartialToString\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36mInternalSerialize\u001b[1;34m(self, write_bytes, deterministic)\u001b[0m\n\u001b[0;32m   1113\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield_value\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mListFields\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1115\u001b[1;33m         \u001b[0mfield_descriptor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrite_bytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1116\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mtag_bytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_bytes\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unknown_fields\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1117\u001b[0m         \u001b[0mwrite_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag_bytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\encoder.py\u001b[0m in \u001b[0;36mEncodeRepeatedField\u001b[1;34m(write, value, deterministic)\u001b[0m\n\u001b[0;32m    758\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m         \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 760\u001b[1;33m         \u001b[0mlocal_EncodeVarint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteSize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    761\u001b[0m         \u001b[0melement\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_InternalSerialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mEncodeRepeatedField\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36mByteSize\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1063\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1064\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield_value\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mListFields\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1065\u001b[1;33m         \u001b[0msize\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfield_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1066\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mtag_bytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_bytes\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unknown_fields\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m         \u001b[0msize\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag_bytes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_bytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\encoder.py\u001b[0m in \u001b[0;36mFieldSize\u001b[1;34m(map_value)\u001b[0m\n\u001b[0;32m    359\u001b[0m       \u001b[1;31m# update the status.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m       \u001b[0mentry_msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmessage_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_concrete_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 361\u001b[1;33m       \u001b[0mtotal\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mmessage_sizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentry_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    362\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mis_message_map\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m         \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteSize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\encoder.py\u001b[0m in \u001b[0;36mFieldSize\u001b[1;34m(value)\u001b[0m\n\u001b[0;32m    306\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mFieldSize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m       \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteSize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mtag_size\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlocal_VarintSize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mFieldSize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36mByteSize\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1060\u001b[0m       \u001b[1;31m# Fields of map entry should always be serialized.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1061\u001b[0m       \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdescriptor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfields_by_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'key'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1062\u001b[1;33m       \u001b[0msize\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mdescriptor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfields_by_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1063\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1064\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield_value\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mListFields\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\encoder.py\u001b[0m in \u001b[0;36mFieldSize\u001b[1;34m(value)\u001b[0m\n\u001b[0;32m    306\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mFieldSize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m       \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteSize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mtag_size\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlocal_VarintSize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mFieldSize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36mByteSize\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1062\u001b[0m       \u001b[0msize\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mdescriptor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfields_by_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1064\u001b[1;33m       \u001b[1;32mfor\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield_value\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mListFields\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1065\u001b[0m         \u001b[0msize\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfield_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1066\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mtag_bytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_bytes\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unknown_fields\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36mListFields\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mListFields\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m     \u001b[0mall_fields\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m_IsPresent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m     \u001b[0mall_fields\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mall_fields\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=32), epochs=80,\n",
    "          validation_data=(x_val, y_val), verbose=1, callbacks = callbacks)\n",
    "    print(\"{} is done\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameter 및 모델 구조 저장\n",
    "##model.save_weights(f'params.LeNet')\n",
    "    \n",
    "#model_json = model.to_json()\n",
    "#with open(f\"Keras_LeNet.json\", \"w\") as json_file : \n",
    "#    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 진행\n",
    "X_test = (test[[str(i) for i in range(784)]] / 255.).values.reshape(-1, 28, 28, 1)\n",
    "#results = model.predict(X_test)\n",
    "submission['digit']=np.argmax(model.predict(X_test),axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission.digit = results\n",
    "submission.to_csv('predict_LeNet_v3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1474 samples, validate on 164 samples\n",
      "Epoch 1/50\n",
      "1474/1474 [==============================] - 1s 428us/sample - loss: 0.4699 - acc: 0.8426 - val_loss: 0.5104 - val_acc: 0.8354\n",
      "Epoch 2/50\n",
      "1474/1474 [==============================] - 1s 430us/sample - loss: 0.4475 - acc: 0.8521 - val_loss: 0.5765 - val_acc: 0.7927\n",
      "Epoch 3/50\n",
      "1474/1474 [==============================] - 1s 453us/sample - loss: 0.4709 - acc: 0.8358 - val_loss: 0.6145 - val_acc: 0.7683\n",
      "Epoch 4/50\n",
      "1474/1474 [==============================] - 1s 436us/sample - loss: 0.3544 - acc: 0.8948 - val_loss: 0.6090 - val_acc: 0.8049\n",
      "Epoch 5/50\n",
      "1474/1474 [==============================] - 1s 516us/sample - loss: 0.3566 - acc: 0.8948 - val_loss: 0.6244 - val_acc: 0.7805\n",
      "Epoch 6/50\n",
      "1474/1474 [==============================] - 1s 454us/sample - loss: 0.2311 - acc: 0.9437 - val_loss: 0.6091 - val_acc: 0.7744\n",
      "Epoch 7/50\n",
      "1474/1474 [==============================] - 1s 442us/sample - loss: 0.1861 - acc: 0.9552 - val_loss: 0.6558 - val_acc: 0.7683\n",
      "Epoch 8/50\n",
      "1474/1474 [==============================] - 1s 457us/sample - loss: 0.1573 - acc: 0.9661 - val_loss: 0.7144 - val_acc: 0.7805\n",
      "Epoch 9/50\n",
      "1474/1474 [==============================] - 1s 445us/sample - loss: 0.1381 - acc: 0.9695 - val_loss: 0.6646 - val_acc: 0.8049\n",
      "Epoch 10/50\n",
      "1474/1474 [==============================] - 1s 474us/sample - loss: 0.1812 - acc: 0.9457 - val_loss: 0.7268 - val_acc: 0.7866\n",
      "Epoch 11/50\n",
      "1474/1474 [==============================] - 1s 475us/sample - loss: 0.0996 - acc: 0.9810 - val_loss: 0.8818 - val_acc: 0.7439\n",
      "Epoch 12/50\n",
      "1474/1474 [==============================] - 1s 434us/sample - loss: 0.1561 - acc: 0.9566 - val_loss: 0.7764 - val_acc: 0.7866\n",
      "Epoch 13/50\n",
      "1474/1474 [==============================] - 1s 436us/sample - loss: 0.0745 - acc: 0.9932 - val_loss: 0.7270 - val_acc: 0.8049\n",
      "Epoch 14/50\n",
      "1474/1474 [==============================] - 1s 440us/sample - loss: 0.0419 - acc: 0.9986 - val_loss: 0.8478 - val_acc: 0.7744\n",
      "Epoch 15/50\n",
      "1474/1474 [==============================] - 1s 422us/sample - loss: 0.0377 - acc: 0.9986 - val_loss: 0.8474 - val_acc: 0.7622\n",
      "Epoch 16/50\n",
      "1474/1474 [==============================] - 1s 437us/sample - loss: 0.0292 - acc: 1.0000 - val_loss: 0.9436 - val_acc: 0.7622\n",
      "Epoch 17/50\n",
      "1474/1474 [==============================] - 1s 413us/sample - loss: 0.0198 - acc: 1.0000 - val_loss: 0.9209 - val_acc: 0.7622\n",
      "Epoch 18/50\n",
      "1474/1474 [==============================] - 1s 434us/sample - loss: 0.0173 - acc: 1.0000 - val_loss: 0.9346 - val_acc: 0.7744\n",
      "Epoch 19/50\n",
      "1474/1474 [==============================] - 1s 433us/sample - loss: 0.0141 - acc: 1.0000 - val_loss: 0.9363 - val_acc: 0.7561\n",
      "Epoch 20/50\n",
      "1474/1474 [==============================] - 1s 420us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.9856 - val_acc: 0.7622\n",
      "Epoch 21/50\n",
      "1474/1474 [==============================] - 1s 427us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 1.0051 - val_acc: 0.7561\n",
      "Epoch 22/50\n",
      "1474/1474 [==============================] - 1s 411us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 1.0096 - val_acc: 0.7561\n",
      "Epoch 23/50\n",
      "1474/1474 [==============================] - 1s 426us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 1.0520 - val_acc: 0.7622\n",
      "Epoch 24/50\n",
      "1474/1474 [==============================] - 1s 417us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 1.0608 - val_acc: 0.7439\n",
      "Epoch 25/50\n",
      "1474/1474 [==============================] - 1s 428us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 1.0904 - val_acc: 0.7500\n",
      "Epoch 26/50\n",
      "1474/1474 [==============================] - 1s 425us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 1.0843 - val_acc: 0.7561\n",
      "Epoch 27/50\n",
      "1474/1474 [==============================] - 1s 447us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 1.0731 - val_acc: 0.7500\n",
      "Epoch 28/50\n",
      "1474/1474 [==============================] - 1s 453us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 1.1240 - val_acc: 0.7378\n",
      "Epoch 29/50\n",
      "1474/1474 [==============================] - 1s 450us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 1.1201 - val_acc: 0.7439\n",
      "Epoch 30/50\n",
      "1474/1474 [==============================] - 1s 434us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 1.1738 - val_acc: 0.7378\n",
      "Epoch 31/50\n",
      "1474/1474 [==============================] - 1s 446us/sample - loss: 0.0041 - acc: 1.0000 - val_loss: 1.1533 - val_acc: 0.7500\n",
      "Epoch 32/50\n",
      "1474/1474 [==============================] - 1s 426us/sample - loss: 0.0039 - acc: 1.0000 - val_loss: 1.1831 - val_acc: 0.7378\n",
      "Epoch 33/50\n",
      "1474/1474 [==============================] - 1s 458us/sample - loss: 0.0034 - acc: 1.0000 - val_loss: 1.1644 - val_acc: 0.7378\n",
      "Epoch 34/50\n",
      "1474/1474 [==============================] - 1s 449us/sample - loss: 0.0032 - acc: 1.0000 - val_loss: 1.2004 - val_acc: 0.7439\n",
      "Epoch 35/50\n",
      "1474/1474 [==============================] - 1s 438us/sample - loss: 0.0030 - acc: 1.0000 - val_loss: 1.2141 - val_acc: 0.7439\n",
      "Epoch 36/50\n",
      "1474/1474 [==============================] - 1s 474us/sample - loss: 0.0028 - acc: 1.0000 - val_loss: 1.2124 - val_acc: 0.7317\n",
      "Epoch 37/50\n",
      "1474/1474 [==============================] - 1s 443us/sample - loss: 0.0026 - acc: 1.0000 - val_loss: 1.2341 - val_acc: 0.7378\n",
      "Epoch 38/50\n",
      "1474/1474 [==============================] - 1s 499us/sample - loss: 0.0025 - acc: 1.0000 - val_loss: 1.2571 - val_acc: 0.7378\n",
      "Epoch 39/50\n",
      "1474/1474 [==============================] - 1s 447us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 1.2634 - val_acc: 0.7317\n",
      "Epoch 40/50\n",
      "1474/1474 [==============================] - 1s 463us/sample - loss: 0.0021 - acc: 1.0000 - val_loss: 1.2658 - val_acc: 0.7317\n",
      "Epoch 41/50\n",
      "1474/1474 [==============================] - 1s 475us/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 1.2718 - val_acc: 0.7317\n",
      "Epoch 42/50\n",
      "1474/1474 [==============================] - 1s 453us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 1.3061 - val_acc: 0.7317\n",
      "Epoch 43/50\n",
      "1474/1474 [==============================] - 1s 444us/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 1.2897 - val_acc: 0.7317\n",
      "Epoch 44/50\n",
      "1474/1474 [==============================] - 1s 546us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 1.3256 - val_acc: 0.7317\n",
      "Epoch 45/50\n",
      "1474/1474 [==============================] - 1s 476us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 1.3435 - val_acc: 0.7256\n",
      "Epoch 46/50\n",
      "1474/1474 [==============================] - 1s 439us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 1.3369 - val_acc: 0.7317\n",
      "Epoch 47/50\n",
      "1474/1474 [==============================] - 1s 474us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 1.3564 - val_acc: 0.7378\n",
      "Epoch 48/50\n",
      "1474/1474 [==============================] - 1s 432us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 1.3310 - val_acc: 0.7256\n",
      "Epoch 49/50\n",
      "1474/1474 [==============================] - 1s 466us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 1.3518 - val_acc: 0.7256\n",
      "Epoch 50/50\n",
      "1474/1474 [==============================] - 1s 439us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 1.3773 - val_acc: 0.7256\n",
      "Train on 1474 samples, validate on 164 samples\n",
      "Epoch 1/50\n",
      "1474/1474 [==============================] - 1s 438us/sample - loss: 0.7323 - acc: 0.7931 - val_loss: 0.5601 - val_acc: 0.8110\n",
      "Epoch 2/50\n",
      "1474/1474 [==============================] - 1s 452us/sample - loss: 0.2688 - acc: 0.9057 - val_loss: 0.2562 - val_acc: 0.9024\n",
      "Epoch 3/50\n",
      "1474/1474 [==============================] - 1s 446us/sample - loss: 0.1608 - acc: 0.9525 - val_loss: 0.2350 - val_acc: 0.9329\n",
      "Epoch 4/50\n",
      "1474/1474 [==============================] - 1s 436us/sample - loss: 0.0913 - acc: 0.9790 - val_loss: 0.2432 - val_acc: 0.8841\n",
      "Epoch 5/50\n",
      "1474/1474 [==============================] - 1s 472us/sample - loss: 0.0312 - acc: 0.9966 - val_loss: 0.1541 - val_acc: 0.9573\n",
      "Epoch 6/50\n",
      "1474/1474 [==============================] - 1s 450us/sample - loss: 0.0165 - acc: 0.9980 - val_loss: 0.1950 - val_acc: 0.9146\n",
      "Epoch 7/50\n",
      "1474/1474 [==============================] - 1s 484us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.1712 - val_acc: 0.9268\n",
      "Epoch 8/50\n",
      "1474/1474 [==============================] - 1s 474us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 0.1589 - val_acc: 0.9268\n",
      "Epoch 9/50\n",
      "1474/1474 [==============================] - 1s 443us/sample - loss: 0.0045 - acc: 1.0000 - val_loss: 0.1684 - val_acc: 0.9329\n",
      "Epoch 10/50\n",
      "1474/1474 [==============================] - 1s 535us/sample - loss: 0.0041 - acc: 1.0000 - val_loss: 0.1546 - val_acc: 0.9512\n",
      "Epoch 11/50\n",
      "1474/1474 [==============================] - 1s 495us/sample - loss: 0.0035 - acc: 1.0000 - val_loss: 0.1581 - val_acc: 0.9451\n",
      "Epoch 12/50\n",
      "1474/1474 [==============================] - 1s 430us/sample - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1489 - val_acc: 0.9329\n",
      "Epoch 13/50\n",
      "1474/1474 [==============================] - 1s 442us/sample - loss: 0.0026 - acc: 1.0000 - val_loss: 0.1543 - val_acc: 0.9451\n",
      "Epoch 14/50\n",
      "1474/1474 [==============================] - 1s 458us/sample - loss: 0.0026 - acc: 1.0000 - val_loss: 0.1455 - val_acc: 0.9512\n",
      "Epoch 15/50\n",
      "1474/1474 [==============================] - 1s 440us/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1483 - val_acc: 0.9512\n",
      "Epoch 16/50\n",
      "1474/1474 [==============================] - 1s 447us/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 0.1489 - val_acc: 0.9512\n",
      "Epoch 17/50\n",
      "1474/1474 [==============================] - 1s 413us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1480 - val_acc: 0.9512\n",
      "Epoch 18/50\n",
      "1474/1474 [==============================] - 1s 426us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1479 - val_acc: 0.9512\n",
      "Epoch 19/50\n",
      "1474/1474 [==============================] - 1s 424us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1447 - val_acc: 0.9451\n",
      "Epoch 20/50\n",
      "1474/1474 [==============================] - 1s 415us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1472 - val_acc: 0.9512\n",
      "Epoch 21/50\n",
      "1474/1474 [==============================] - 1s 439us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1401 - val_acc: 0.9512\n",
      "Epoch 22/50\n",
      "1474/1474 [==============================] - 1s 432us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1408 - val_acc: 0.9573\n",
      "Epoch 23/50\n",
      "1474/1474 [==============================] - 1s 475us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1368 - val_acc: 0.9451\n",
      "Epoch 24/50\n",
      "1474/1474 [==============================] - 1s 451us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1402 - val_acc: 0.9573\n",
      "Epoch 25/50\n",
      "1474/1474 [==============================] - 1s 451us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1413 - val_acc: 0.9573\n",
      "Epoch 26/50\n",
      "1474/1474 [==============================] - 1s 477us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.1433 - val_acc: 0.9573\n",
      "Epoch 27/50\n",
      "1474/1474 [==============================] - 1s 451us/sample - loss: 9.7832e-04 - acc: 1.0000 - val_loss: 0.1356 - val_acc: 0.9573\n",
      "Epoch 28/50\n",
      "1474/1474 [==============================] - 1s 449us/sample - loss: 9.3233e-04 - acc: 1.0000 - val_loss: 0.1390 - val_acc: 0.9573\n",
      "Epoch 29/50\n",
      "1474/1474 [==============================] - 1s 447us/sample - loss: 9.0282e-04 - acc: 1.0000 - val_loss: 0.1359 - val_acc: 0.9573\n",
      "Epoch 30/50\n",
      "1474/1474 [==============================] - 1s 445us/sample - loss: 8.3941e-04 - acc: 1.0000 - val_loss: 0.1390 - val_acc: 0.9573\n",
      "Epoch 31/50\n",
      "1474/1474 [==============================] - 1s 472us/sample - loss: 8.0454e-04 - acc: 1.0000 - val_loss: 0.1380 - val_acc: 0.9573\n",
      "Epoch 32/50\n",
      "1474/1474 [==============================] - 1s 452us/sample - loss: 7.6392e-04 - acc: 1.0000 - val_loss: 0.1373 - val_acc: 0.9573\n",
      "Epoch 33/50\n",
      "1474/1474 [==============================] - 1s 441us/sample - loss: 7.2586e-04 - acc: 1.0000 - val_loss: 0.1389 - val_acc: 0.9573\n",
      "Epoch 34/50\n",
      "1474/1474 [==============================] - 1s 455us/sample - loss: 6.9457e-04 - acc: 1.0000 - val_loss: 0.1366 - val_acc: 0.9573\n",
      "Epoch 35/50\n",
      "1474/1474 [==============================] - 1s 453us/sample - loss: 6.6443e-04 - acc: 1.0000 - val_loss: 0.1380 - val_acc: 0.9573\n",
      "Epoch 36/50\n",
      "1474/1474 [==============================] - 1s 452us/sample - loss: 6.4262e-04 - acc: 1.0000 - val_loss: 0.1407 - val_acc: 0.9573\n",
      "Epoch 37/50\n",
      "1474/1474 [==============================] - 1s 452us/sample - loss: 6.1535e-04 - acc: 1.0000 - val_loss: 0.1392 - val_acc: 0.9573\n",
      "Epoch 38/50\n",
      "1474/1474 [==============================] - 1s 435us/sample - loss: 5.9886e-04 - acc: 1.0000 - val_loss: 0.1403 - val_acc: 0.9573\n",
      "Epoch 39/50\n",
      "1474/1474 [==============================] - 1s 441us/sample - loss: 5.6107e-04 - acc: 1.0000 - val_loss: 0.1379 - val_acc: 0.9573\n",
      "Epoch 40/50\n",
      "1474/1474 [==============================] - 1s 461us/sample - loss: 5.3587e-04 - acc: 1.0000 - val_loss: 0.1397 - val_acc: 0.9573\n",
      "Epoch 41/50\n",
      "1474/1474 [==============================] - 1s 441us/sample - loss: 5.1794e-04 - acc: 1.0000 - val_loss: 0.1345 - val_acc: 0.9573\n",
      "Epoch 42/50\n",
      "1474/1474 [==============================] - 1s 457us/sample - loss: 4.9722e-04 - acc: 1.0000 - val_loss: 0.1378 - val_acc: 0.9573\n",
      "Epoch 43/50\n",
      "1474/1474 [==============================] - 1s 440us/sample - loss: 4.7555e-04 - acc: 1.0000 - val_loss: 0.1361 - val_acc: 0.9573\n",
      "Epoch 44/50\n",
      "1474/1474 [==============================] - 1s 457us/sample - loss: 4.6800e-04 - acc: 1.0000 - val_loss: 0.1377 - val_acc: 0.9573\n",
      "Epoch 45/50\n",
      "1474/1474 [==============================] - 1s 457us/sample - loss: 4.5115e-04 - acc: 1.0000 - val_loss: 0.1391 - val_acc: 0.9573\n",
      "Epoch 46/50\n",
      "1474/1474 [==============================] - 1s 440us/sample - loss: 4.3020e-04 - acc: 1.0000 - val_loss: 0.1386 - val_acc: 0.9573\n",
      "Epoch 47/50\n",
      "1474/1474 [==============================] - 1s 450us/sample - loss: 4.0438e-04 - acc: 1.0000 - val_loss: 0.1386 - val_acc: 0.9573\n",
      "Epoch 48/50\n",
      "1474/1474 [==============================] - 1s 443us/sample - loss: 3.9312e-04 - acc: 1.0000 - val_loss: 0.1368 - val_acc: 0.9573\n",
      "Epoch 49/50\n",
      "1474/1474 [==============================] - 1s 449us/sample - loss: 3.7556e-04 - acc: 1.0000 - val_loss: 0.1366 - val_acc: 0.9573\n",
      "Epoch 50/50\n",
      "1474/1474 [==============================] - 1s 434us/sample - loss: 3.6141e-04 - acc: 1.0000 - val_loss: 0.1380 - val_acc: 0.9573\n",
      "Train on 1474 samples, validate on 164 samples\n",
      "Epoch 1/50\n",
      "1474/1474 [==============================] - 1s 459us/sample - loss: 0.4923 - acc: 0.8616 - val_loss: 0.4155 - val_acc: 0.8232\n",
      "Epoch 2/50\n",
      "1474/1474 [==============================] - 1s 465us/sample - loss: 0.3099 - acc: 0.8894 - val_loss: 0.2166 - val_acc: 0.9085\n",
      "Epoch 3/50\n",
      "1474/1474 [==============================] - 1s 434us/sample - loss: 0.0863 - acc: 0.9735 - val_loss: 0.1795 - val_acc: 0.9268\n",
      "Epoch 4/50\n",
      "1474/1474 [==============================] - 1s 427us/sample - loss: 0.0260 - acc: 0.9966 - val_loss: 0.1201 - val_acc: 0.9512\n",
      "Epoch 5/50\n",
      "1474/1474 [==============================] - 1s 432us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.0849 - val_acc: 0.9695\n",
      "Epoch 6/50\n",
      "1474/1474 [==============================] - 1s 424us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0825 - val_acc: 0.9695\n",
      "Epoch 7/50\n",
      "1474/1474 [==============================] - 1s 427us/sample - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0783 - val_acc: 0.9756\n",
      "Epoch 8/50\n",
      "1474/1474 [==============================] - 1s 424us/sample - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0771 - val_acc: 0.9756\n",
      "Epoch 9/50\n",
      "1474/1474 [==============================] - 1s 430us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0731 - val_acc: 0.9756\n",
      "Epoch 10/50\n",
      "1474/1474 [==============================] - 1s 436us/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0759 - val_acc: 0.9756\n",
      "Epoch 11/50\n",
      "1474/1474 [==============================] - 1s 495us/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0761 - val_acc: 0.9756\n",
      "Epoch 12/50\n",
      "1474/1474 [==============================] - 1s 465us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0721 - val_acc: 0.9817\n",
      "Epoch 13/50\n",
      "1474/1474 [==============================] - 1s 459us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0743 - val_acc: 0.9817\n",
      "Epoch 14/50\n",
      "1474/1474 [==============================] - 1s 448us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0693 - val_acc: 0.9756\n",
      "Epoch 15/50\n",
      "1474/1474 [==============================] - 1s 525us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0697 - val_acc: 0.9756\n",
      "Epoch 16/50\n",
      "1474/1474 [==============================] - 1s 466us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0692 - val_acc: 0.9756\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1474/1474 [==============================] - 1s 437us/sample - loss: 9.4712e-04 - acc: 1.0000 - val_loss: 0.0678 - val_acc: 0.9756\n",
      "Epoch 18/50\n",
      "1474/1474 [==============================] - 1s 462us/sample - loss: 9.1377e-04 - acc: 1.0000 - val_loss: 0.0664 - val_acc: 0.9817\n",
      "Epoch 19/50\n",
      "1474/1474 [==============================] - 1s 466us/sample - loss: 8.1859e-04 - acc: 1.0000 - val_loss: 0.0666 - val_acc: 0.9817\n",
      "Epoch 20/50\n",
      "1474/1474 [==============================] - 1s 438us/sample - loss: 7.5268e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9817\n",
      "Epoch 21/50\n",
      "1474/1474 [==============================] - 1s 461us/sample - loss: 7.0696e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9817\n",
      "Epoch 22/50\n",
      "1474/1474 [==============================] - 1s 459us/sample - loss: 6.8181e-04 - acc: 1.0000 - val_loss: 0.0640 - val_acc: 0.9817\n",
      "Epoch 23/50\n",
      "1474/1474 [==============================] - 1s 474us/sample - loss: 6.3302e-04 - acc: 1.0000 - val_loss: 0.0638 - val_acc: 0.9817\n",
      "Epoch 24/50\n",
      "1474/1474 [==============================] - 1s 449us/sample - loss: 5.8752e-04 - acc: 1.0000 - val_loss: 0.0632 - val_acc: 0.9817\n",
      "Epoch 25/50\n",
      "1474/1474 [==============================] - 1s 448us/sample - loss: 5.5406e-04 - acc: 1.0000 - val_loss: 0.0644 - val_acc: 0.9817\n",
      "Epoch 26/50\n",
      "1474/1474 [==============================] - 1s 462us/sample - loss: 5.1944e-04 - acc: 1.0000 - val_loss: 0.0631 - val_acc: 0.9817\n",
      "Epoch 27/50\n",
      "1474/1474 [==============================] - 1s 462us/sample - loss: 4.9002e-04 - acc: 1.0000 - val_loss: 0.0635 - val_acc: 0.9817\n",
      "Epoch 28/50\n",
      "1474/1474 [==============================] - 1s 444us/sample - loss: 4.6396e-04 - acc: 1.0000 - val_loss: 0.0626 - val_acc: 0.9817\n",
      "Epoch 29/50\n",
      "1474/1474 [==============================] - 1s 444us/sample - loss: 4.4224e-04 - acc: 1.0000 - val_loss: 0.0633 - val_acc: 0.9817\n",
      "Epoch 30/50\n",
      "1474/1474 [==============================] - 1s 444us/sample - loss: 4.2485e-04 - acc: 1.0000 - val_loss: 0.0613 - val_acc: 0.9817\n",
      "Epoch 31/50\n",
      "1474/1474 [==============================] - 1s 454us/sample - loss: 4.0015e-04 - acc: 1.0000 - val_loss: 0.0627 - val_acc: 0.9817\n",
      "Epoch 32/50\n",
      "1474/1474 [==============================] - 1s 467us/sample - loss: 3.8056e-04 - acc: 1.0000 - val_loss: 0.0608 - val_acc: 0.9817\n",
      "Epoch 33/50\n",
      "1474/1474 [==============================] - 1s 448us/sample - loss: 3.6245e-04 - acc: 1.0000 - val_loss: 0.0610 - val_acc: 0.9817\n",
      "Epoch 34/50\n",
      "1474/1474 [==============================] - 1s 461us/sample - loss: 3.4709e-04 - acc: 1.0000 - val_loss: 0.0603 - val_acc: 0.9817\n",
      "Epoch 35/50\n",
      "1474/1474 [==============================] - 1s 436us/sample - loss: 3.3179e-04 - acc: 1.0000 - val_loss: 0.0620 - val_acc: 0.9756\n",
      "Epoch 36/50\n",
      "1474/1474 [==============================] - 1s 472us/sample - loss: 3.1653e-04 - acc: 1.0000 - val_loss: 0.0596 - val_acc: 0.9817\n",
      "Epoch 37/50\n",
      "1474/1474 [==============================] - 1s 472us/sample - loss: 3.0239e-04 - acc: 1.0000 - val_loss: 0.0606 - val_acc: 0.9817\n",
      "Epoch 38/50\n",
      "1474/1474 [==============================] - 1s 488us/sample - loss: 2.9408e-04 - acc: 1.0000 - val_loss: 0.0592 - val_acc: 0.9817\n",
      "Epoch 39/50\n",
      "1474/1474 [==============================] - 1s 450us/sample - loss: 2.7997e-04 - acc: 1.0000 - val_loss: 0.0599 - val_acc: 0.9817\n",
      "Epoch 40/50\n",
      "1474/1474 [==============================] - 1s 453us/sample - loss: 2.7034e-04 - acc: 1.0000 - val_loss: 0.0615 - val_acc: 0.9817\n",
      "Epoch 41/50\n",
      "1474/1474 [==============================] - 1s 438us/sample - loss: 2.5780e-04 - acc: 1.0000 - val_loss: 0.0607 - val_acc: 0.9817\n",
      "Epoch 42/50\n",
      "1474/1474 [==============================] - 1s 454us/sample - loss: 2.4719e-04 - acc: 1.0000 - val_loss: 0.0589 - val_acc: 0.9817\n",
      "Epoch 43/50\n",
      "1474/1474 [==============================] - 1s 469us/sample - loss: 2.3765e-04 - acc: 1.0000 - val_loss: 0.0574 - val_acc: 0.9817\n",
      "Epoch 44/50\n",
      "1474/1474 [==============================] - 1s 441us/sample - loss: 2.2840e-04 - acc: 1.0000 - val_loss: 0.0592 - val_acc: 0.9817\n",
      "Epoch 45/50\n",
      "1474/1474 [==============================] - 1s 474us/sample - loss: 2.1979e-04 - acc: 1.0000 - val_loss: 0.0590 - val_acc: 0.9817\n",
      "Epoch 46/50\n",
      "1474/1474 [==============================] - 1s 435us/sample - loss: 2.1144e-04 - acc: 1.0000 - val_loss: 0.0585 - val_acc: 0.9817\n",
      "Epoch 47/50\n",
      "1474/1474 [==============================] - 1s 451us/sample - loss: 2.0311e-04 - acc: 1.0000 - val_loss: 0.0577 - val_acc: 0.9817\n",
      "Epoch 48/50\n",
      "1474/1474 [==============================] - 1s 460us/sample - loss: 1.9708e-04 - acc: 1.0000 - val_loss: 0.0576 - val_acc: 0.9817\n",
      "Epoch 49/50\n",
      "1474/1474 [==============================] - 1s 428us/sample - loss: 1.8962e-04 - acc: 1.0000 - val_loss: 0.0559 - val_acc: 0.9817\n",
      "Epoch 50/50\n",
      "1474/1474 [==============================] - 1s 462us/sample - loss: 1.8263e-04 - acc: 1.0000 - val_loss: 0.0565 - val_acc: 0.9817\n",
      "Train on 1474 samples, validate on 164 samples\n",
      "Epoch 1/50\n",
      "1474/1474 [==============================] - 1s 548us/sample - loss: 0.2610 - acc: 0.9240 - val_loss: 0.4994 - val_acc: 0.8293\n",
      "Epoch 2/50\n",
      "1474/1474 [==============================] - 1s 484us/sample - loss: 0.4233 - acc: 0.8555 - val_loss: 0.4012 - val_acc: 0.8659\n",
      "Epoch 3/50\n",
      "1474/1474 [==============================] - 1s 459us/sample - loss: 0.0831 - acc: 0.9796 - val_loss: 0.1727 - val_acc: 0.9512\n",
      "Epoch 4/50\n",
      "1474/1474 [==============================] - 1s 446us/sample - loss: 0.0208 - acc: 0.9973 - val_loss: 0.1759 - val_acc: 0.9512\n",
      "Epoch 5/50\n",
      "1474/1474 [==============================] - 1s 443us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.1430 - val_acc: 0.9573\n",
      "Epoch 6/50\n",
      "1474/1474 [==============================] - 1s 450us/sample - loss: 0.0036 - acc: 1.0000 - val_loss: 0.1419 - val_acc: 0.9451\n",
      "Epoch 7/50\n",
      "1474/1474 [==============================] - 1s 424us/sample - loss: 0.0027 - acc: 1.0000 - val_loss: 0.1317 - val_acc: 0.9634\n",
      "Epoch 8/50\n",
      "1474/1474 [==============================] - 1s 434us/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1291 - val_acc: 0.9695\n",
      "Epoch 9/50\n",
      "1474/1474 [==============================] - 1s 465us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1284 - val_acc: 0.9695\n",
      "Epoch 10/50\n",
      "1474/1474 [==============================] - 1s 434us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1195 - val_acc: 0.9695\n",
      "Epoch 11/50\n",
      "1474/1474 [==============================] - 1s 447us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1213 - val_acc: 0.9695\n",
      "Epoch 12/50\n",
      "1474/1474 [==============================] - 1s 427us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1180 - val_acc: 0.9695\n",
      "Epoch 13/50\n",
      "1474/1474 [==============================] - 1s 440us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1177 - val_acc: 0.9695\n",
      "Epoch 14/50\n",
      "1474/1474 [==============================] - 1s 451us/sample - loss: 9.7301e-04 - acc: 1.0000 - val_loss: 0.1162 - val_acc: 0.9695\n",
      "Epoch 15/50\n",
      "1474/1474 [==============================] - 1s 437us/sample - loss: 8.8520e-04 - acc: 1.0000 - val_loss: 0.1152 - val_acc: 0.9756\n",
      "Epoch 16/50\n",
      "1474/1474 [==============================] - 1s 463us/sample - loss: 8.1145e-04 - acc: 1.0000 - val_loss: 0.1136 - val_acc: 0.9756\n",
      "Epoch 17/50\n",
      "1474/1474 [==============================] - 1s 448us/sample - loss: 7.5522e-04 - acc: 1.0000 - val_loss: 0.1124 - val_acc: 0.9756\n",
      "Epoch 18/50\n",
      "1474/1474 [==============================] - 1s 441us/sample - loss: 6.8980e-04 - acc: 1.0000 - val_loss: 0.1128 - val_acc: 0.9695\n",
      "Epoch 19/50\n",
      "1474/1474 [==============================] - 1s 475us/sample - loss: 6.4234e-04 - acc: 1.0000 - val_loss: 0.1113 - val_acc: 0.9695\n",
      "Epoch 20/50\n",
      "1474/1474 [==============================] - 1s 480us/sample - loss: 5.9940e-04 - acc: 1.0000 - val_loss: 0.1119 - val_acc: 0.9695\n",
      "Epoch 21/50\n",
      "1474/1474 [==============================] - 1s 472us/sample - loss: 5.5944e-04 - acc: 1.0000 - val_loss: 0.1106 - val_acc: 0.9695\n",
      "Epoch 22/50\n",
      "1474/1474 [==============================] - 1s 489us/sample - loss: 5.2590e-04 - acc: 1.0000 - val_loss: 0.1100 - val_acc: 0.9695\n",
      "Epoch 23/50\n",
      "1474/1474 [==============================] - 1s 449us/sample - loss: 4.9371e-04 - acc: 1.0000 - val_loss: 0.1095 - val_acc: 0.9695\n",
      "Epoch 24/50\n",
      "1474/1474 [==============================] - 1s 465us/sample - loss: 4.6501e-04 - acc: 1.0000 - val_loss: 0.1089 - val_acc: 0.9695\n",
      "Epoch 25/50\n",
      "1474/1474 [==============================] - 1s 452us/sample - loss: 4.3957e-04 - acc: 1.0000 - val_loss: 0.1086 - val_acc: 0.9695\n",
      "Epoch 26/50\n",
      "1474/1474 [==============================] - 1s 461us/sample - loss: 4.1539e-04 - acc: 1.0000 - val_loss: 0.1086 - val_acc: 0.9756\n",
      "Epoch 27/50\n",
      "1474/1474 [==============================] - 1s 449us/sample - loss: 3.9343e-04 - acc: 1.0000 - val_loss: 0.1086 - val_acc: 0.9756\n",
      "Epoch 28/50\n",
      "1474/1474 [==============================] - 1s 448us/sample - loss: 3.7733e-04 - acc: 1.0000 - val_loss: 0.1076 - val_acc: 0.9756\n",
      "Epoch 29/50\n",
      "1474/1474 [==============================] - 1s 439us/sample - loss: 3.5467e-04 - acc: 1.0000 - val_loss: 0.1069 - val_acc: 0.9756\n",
      "Epoch 30/50\n",
      "1474/1474 [==============================] - 1s 440us/sample - loss: 3.4256e-04 - acc: 1.0000 - val_loss: 0.1046 - val_acc: 0.9756\n",
      "Epoch 31/50\n",
      "1474/1474 [==============================] - 1s 428us/sample - loss: 3.2041e-04 - acc: 1.0000 - val_loss: 0.1058 - val_acc: 0.9756\n",
      "Epoch 32/50\n",
      "1474/1474 [==============================] - 1s 458us/sample - loss: 3.0322e-04 - acc: 1.0000 - val_loss: 0.1046 - val_acc: 0.9756\n",
      "Epoch 33/50\n",
      "1474/1474 [==============================] - 1s 453us/sample - loss: 2.8979e-04 - acc: 1.0000 - val_loss: 0.1061 - val_acc: 0.9756\n",
      "Epoch 34/50\n",
      "1474/1474 [==============================] - 1s 453us/sample - loss: 2.7485e-04 - acc: 1.0000 - val_loss: 0.1059 - val_acc: 0.9756\n",
      "Epoch 35/50\n",
      "1474/1474 [==============================] - 1s 459us/sample - loss: 2.6271e-04 - acc: 1.0000 - val_loss: 0.1047 - val_acc: 0.9756\n",
      "Epoch 36/50\n",
      "1474/1474 [==============================] - 1s 427us/sample - loss: 2.5078e-04 - acc: 1.0000 - val_loss: 0.1048 - val_acc: 0.9756\n",
      "Epoch 37/50\n",
      "1474/1474 [==============================] - 1s 448us/sample - loss: 2.4003e-04 - acc: 1.0000 - val_loss: 0.1050 - val_acc: 0.9756\n",
      "Epoch 38/50\n",
      "1474/1474 [==============================] - 1s 451us/sample - loss: 2.3007e-04 - acc: 1.0000 - val_loss: 0.1046 - val_acc: 0.9756\n",
      "Epoch 39/50\n",
      "1474/1474 [==============================] - 1s 431us/sample - loss: 2.2066e-04 - acc: 1.0000 - val_loss: 0.1041 - val_acc: 0.9756\n",
      "Epoch 40/50\n",
      "1474/1474 [==============================] - 1s 446us/sample - loss: 2.1235e-04 - acc: 1.0000 - val_loss: 0.1055 - val_acc: 0.9756\n",
      "Epoch 41/50\n",
      "1474/1474 [==============================] - 1s 431us/sample - loss: 2.0254e-04 - acc: 1.0000 - val_loss: 0.1045 - val_acc: 0.9756\n",
      "Epoch 42/50\n",
      "1474/1474 [==============================] - 1s 456us/sample - loss: 1.9431e-04 - acc: 1.0000 - val_loss: 0.1039 - val_acc: 0.9756\n",
      "Epoch 43/50\n",
      "1474/1474 [==============================] - 1s 465us/sample - loss: 1.8629e-04 - acc: 1.0000 - val_loss: 0.1042 - val_acc: 0.9756\n",
      "Epoch 44/50\n",
      "1474/1474 [==============================] - 1s 449us/sample - loss: 1.7931e-04 - acc: 1.0000 - val_loss: 0.1036 - val_acc: 0.9756\n",
      "Epoch 45/50\n",
      "1474/1474 [==============================] - 1s 490us/sample - loss: 1.7326e-04 - acc: 1.0000 - val_loss: 0.1034 - val_acc: 0.9756\n",
      "Epoch 46/50\n",
      "1474/1474 [==============================] - 1s 477us/sample - loss: 1.6604e-04 - acc: 1.0000 - val_loss: 0.1033 - val_acc: 0.9756\n",
      "Epoch 47/50\n",
      "1474/1474 [==============================] - 1s 493us/sample - loss: 1.6020e-04 - acc: 1.0000 - val_loss: 0.1030 - val_acc: 0.9756\n",
      "Epoch 48/50\n",
      "1474/1474 [==============================] - 1s 471us/sample - loss: 1.5423e-04 - acc: 1.0000 - val_loss: 0.1031 - val_acc: 0.9756\n",
      "Epoch 49/50\n",
      "1474/1474 [==============================] - 1s 451us/sample - loss: 1.4903e-04 - acc: 1.0000 - val_loss: 0.1031 - val_acc: 0.9756\n",
      "Epoch 50/50\n",
      "1474/1474 [==============================] - 1s 426us/sample - loss: 1.4372e-04 - acc: 1.0000 - val_loss: 0.1022 - val_acc: 0.9756\n",
      "Train on 1474 samples, validate on 164 samples\n",
      "Epoch 1/50\n",
      "1474/1474 [==============================] - 1s 453us/sample - loss: 0.2345 - acc: 0.9437 - val_loss: 0.2915 - val_acc: 0.9146\n",
      "Epoch 2/50\n",
      "1474/1474 [==============================] - 1s 447us/sample - loss: 0.1406 - acc: 0.9505 - val_loss: 0.1460 - val_acc: 0.9268\n",
      "Epoch 3/50\n",
      "1474/1474 [==============================] - 1s 454us/sample - loss: 0.0670 - acc: 0.9763 - val_loss: 0.0757 - val_acc: 0.9878\n",
      "Epoch 4/50\n",
      "1474/1474 [==============================] - 1s 451us/sample - loss: 0.1321 - acc: 0.9552 - val_loss: 0.2288 - val_acc: 0.9146\n",
      "Epoch 5/50\n",
      "1474/1474 [==============================] - 1s 438us/sample - loss: 0.0611 - acc: 0.9810 - val_loss: 0.0682 - val_acc: 0.9817\n",
      "Epoch 6/50\n",
      "1474/1474 [==============================] - 1s 461us/sample - loss: 0.0164 - acc: 0.9959 - val_loss: 0.0791 - val_acc: 0.9756\n",
      "Epoch 7/50\n",
      "1474/1474 [==============================] - 1s 443us/sample - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0435 - val_acc: 0.9817\n",
      "Epoch 8/50\n",
      "1474/1474 [==============================] - 1s 451us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0395 - val_acc: 0.9756\n",
      "Epoch 9/50\n",
      "1474/1474 [==============================] - 1s 441us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0368 - val_acc: 0.9878\n",
      "Epoch 10/50\n",
      "1474/1474 [==============================] - 1s 424us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0332 - val_acc: 0.9878\n",
      "Epoch 11/50\n",
      "1474/1474 [==============================] - 1s 458us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0353 - val_acc: 0.9878\n",
      "Epoch 12/50\n",
      "1474/1474 [==============================] - 1s 440us/sample - loss: 8.5406e-04 - acc: 1.0000 - val_loss: 0.0326 - val_acc: 0.9939\n",
      "Epoch 13/50\n",
      "1474/1474 [==============================] - 1s 448us/sample - loss: 7.5668e-04 - acc: 1.0000 - val_loss: 0.0316 - val_acc: 0.9939\n",
      "Epoch 14/50\n",
      "1474/1474 [==============================] - 1s 447us/sample - loss: 6.8052e-04 - acc: 1.0000 - val_loss: 0.0311 - val_acc: 0.9939\n",
      "Epoch 15/50\n",
      "1474/1474 [==============================] - 1s 424us/sample - loss: 6.2205e-04 - acc: 1.0000 - val_loss: 0.0306 - val_acc: 0.9939\n",
      "Epoch 16/50\n",
      "1474/1474 [==============================] - 1s 445us/sample - loss: 5.6227e-04 - acc: 1.0000 - val_loss: 0.0288 - val_acc: 0.9939\n",
      "Epoch 17/50\n",
      "1474/1474 [==============================] - 1s 442us/sample - loss: 5.1283e-04 - acc: 1.0000 - val_loss: 0.0283 - val_acc: 0.9939\n",
      "Epoch 18/50\n",
      "1474/1474 [==============================] - 1s 436us/sample - loss: 4.7553e-04 - acc: 1.0000 - val_loss: 0.0279 - val_acc: 0.9939\n",
      "Epoch 19/50\n",
      "1474/1474 [==============================] - 1s 456us/sample - loss: 4.4119e-04 - acc: 1.0000 - val_loss: 0.0271 - val_acc: 0.9939\n",
      "Epoch 20/50\n",
      "1474/1474 [==============================] - 1s 443us/sample - loss: 4.1062e-04 - acc: 1.0000 - val_loss: 0.0264 - val_acc: 0.9939\n",
      "Epoch 21/50\n",
      "1474/1474 [==============================] - 1s 440us/sample - loss: 3.8552e-04 - acc: 1.0000 - val_loss: 0.0262 - val_acc: 0.9939\n",
      "Epoch 22/50\n",
      "1474/1474 [==============================] - 1s 465us/sample - loss: 3.5919e-04 - acc: 1.0000 - val_loss: 0.0266 - val_acc: 0.9939\n",
      "Epoch 23/50\n",
      "1474/1474 [==============================] - 1s 452us/sample - loss: 3.3726e-04 - acc: 1.0000 - val_loss: 0.0257 - val_acc: 0.9939\n",
      "Epoch 24/50\n",
      "1474/1474 [==============================] - 1s 465us/sample - loss: 3.1828e-04 - acc: 1.0000 - val_loss: 0.0251 - val_acc: 0.9939\n",
      "Epoch 25/50\n",
      "1474/1474 [==============================] - 1s 463us/sample - loss: 3.0036e-04 - acc: 1.0000 - val_loss: 0.0249 - val_acc: 0.9939\n",
      "Epoch 26/50\n",
      "1474/1474 [==============================] - 1s 454us/sample - loss: 2.8462e-04 - acc: 1.0000 - val_loss: 0.0243 - val_acc: 0.9939\n",
      "Epoch 27/50\n",
      "1474/1474 [==============================] - 1s 465us/sample - loss: 2.6940e-04 - acc: 1.0000 - val_loss: 0.0237 - val_acc: 0.9939\n",
      "Epoch 28/50\n",
      "1474/1474 [==============================] - 1s 462us/sample - loss: 2.5601e-04 - acc: 1.0000 - val_loss: 0.0236 - val_acc: 0.9939\n",
      "Epoch 29/50\n",
      "1474/1474 [==============================] - 1s 453us/sample - loss: 2.4318e-04 - acc: 1.0000 - val_loss: 0.0235 - val_acc: 0.9939\n",
      "Epoch 30/50\n",
      "1474/1474 [==============================] - 1s 465us/sample - loss: 2.3128e-04 - acc: 1.0000 - val_loss: 0.0230 - val_acc: 0.9939\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1474/1474 [==============================] - 1s 451us/sample - loss: 2.2026e-04 - acc: 1.0000 - val_loss: 0.0230 - val_acc: 0.9939\n",
      "Epoch 32/50\n",
      "1474/1474 [==============================] - 1s 453us/sample - loss: 2.1833e-04 - acc: 1.0000 - val_loss: 0.0230 - val_acc: 0.9939\n",
      "Epoch 33/50\n",
      "1474/1474 [==============================] - 1s 462us/sample - loss: 2.0354e-04 - acc: 1.0000 - val_loss: 0.0228 - val_acc: 0.9939\n",
      "Epoch 34/50\n",
      "1474/1474 [==============================] - 1s 462us/sample - loss: 1.9178e-04 - acc: 1.0000 - val_loss: 0.0226 - val_acc: 0.9939\n",
      "Epoch 35/50\n",
      "1474/1474 [==============================] - 1s 507us/sample - loss: 1.8286e-04 - acc: 1.0000 - val_loss: 0.0225 - val_acc: 0.9939\n",
      "Epoch 36/50\n",
      "1474/1474 [==============================] - 1s 475us/sample - loss: 1.7482e-04 - acc: 1.0000 - val_loss: 0.0225 - val_acc: 0.9939\n",
      "Epoch 37/50\n",
      "1474/1474 [==============================] - 1s 483us/sample - loss: 1.6702e-04 - acc: 1.0000 - val_loss: 0.0223 - val_acc: 0.9939\n",
      "Epoch 38/50\n",
      "1474/1474 [==============================] - 1s 523us/sample - loss: 1.6005e-04 - acc: 1.0000 - val_loss: 0.0222 - val_acc: 0.9939\n",
      "Epoch 39/50\n",
      "1474/1474 [==============================] - 1s 504us/sample - loss: 1.5380e-04 - acc: 1.0000 - val_loss: 0.0217 - val_acc: 0.9939\n",
      "Epoch 40/50\n",
      "1474/1474 [==============================] - 1s 475us/sample - loss: 1.4761e-04 - acc: 1.0000 - val_loss: 0.0215 - val_acc: 0.9939\n",
      "Epoch 41/50\n",
      "1474/1474 [==============================] - 1s 497us/sample - loss: 1.4156e-04 - acc: 1.0000 - val_loss: 0.0213 - val_acc: 0.9939\n",
      "Epoch 42/50\n",
      "1474/1474 [==============================] - 1s 457us/sample - loss: 1.3631e-04 - acc: 1.0000 - val_loss: 0.0211 - val_acc: 0.9939\n",
      "Epoch 43/50\n",
      "1474/1474 [==============================] - 1s 470us/sample - loss: 1.3124e-04 - acc: 1.0000 - val_loss: 0.0210 - val_acc: 0.9939\n",
      "Epoch 44/50\n",
      "1474/1474 [==============================] - 1s 484us/sample - loss: 1.2619e-04 - acc: 1.0000 - val_loss: 0.0207 - val_acc: 0.9939\n",
      "Epoch 45/50\n",
      "1474/1474 [==============================] - 1s 466us/sample - loss: 1.2177e-04 - acc: 1.0000 - val_loss: 0.0204 - val_acc: 0.9939\n",
      "Epoch 46/50\n",
      "1474/1474 [==============================] - 1s 461us/sample - loss: 1.1733e-04 - acc: 1.0000 - val_loss: 0.0203 - val_acc: 0.9939\n",
      "Epoch 47/50\n",
      "1474/1474 [==============================] - 1s 473us/sample - loss: 1.1332e-04 - acc: 1.0000 - val_loss: 0.0200 - val_acc: 0.9939\n",
      "Epoch 48/50\n",
      "1474/1474 [==============================] - 1s 497us/sample - loss: 1.0920e-04 - acc: 1.0000 - val_loss: 0.0199 - val_acc: 0.9939\n",
      "Epoch 49/50\n",
      "1474/1474 [==============================] - 1s 489us/sample - loss: 1.0519e-04 - acc: 1.0000 - val_loss: 0.0198 - val_acc: 0.9939\n",
      "Epoch 50/50\n",
      "1474/1474 [==============================] - 1s 476us/sample - loss: 1.0146e-04 - acc: 1.0000 - val_loss: 0.0195 - val_acc: 0.9939\n",
      "Train on 1474 samples, validate on 164 samples\n",
      "Epoch 1/50\n",
      "1474/1474 [==============================] - 1s 498us/sample - loss: 0.0307 - acc: 0.9885 - val_loss: 0.1046 - val_acc: 0.9573\n",
      "Epoch 2/50\n",
      "1474/1474 [==============================] - 1s 468us/sample - loss: 0.2297 - acc: 0.9294 - val_loss: 0.2133 - val_acc: 0.9390\n",
      "Epoch 3/50\n",
      "1474/1474 [==============================] - 1s 503us/sample - loss: 0.1141 - acc: 0.9586 - val_loss: 0.1463 - val_acc: 0.9451\n",
      "Epoch 4/50\n",
      "1474/1474 [==============================] - 1s 528us/sample - loss: 0.0194 - acc: 0.9966 - val_loss: 0.0497 - val_acc: 0.9878\n",
      "Epoch 5/50\n",
      "1474/1474 [==============================] - 1s 520us/sample - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0390 - val_acc: 0.9939\n",
      "Epoch 6/50\n",
      "1474/1474 [==============================] - 1s 527us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0407 - val_acc: 0.9939\n",
      "Epoch 7/50\n",
      "1474/1474 [==============================] - 1s 506us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0401 - val_acc: 0.9939\n",
      "Epoch 8/50\n",
      "1474/1474 [==============================] - 1s 503us/sample - loss: 8.5313e-04 - acc: 1.0000 - val_loss: 0.0397 - val_acc: 0.9939\n",
      "Epoch 9/50\n",
      "1474/1474 [==============================] - 1s 489us/sample - loss: 7.2211e-04 - acc: 1.0000 - val_loss: 0.0384 - val_acc: 0.9939\n",
      "Epoch 10/50\n",
      "1474/1474 [==============================] - 1s 503us/sample - loss: 6.2728e-04 - acc: 1.0000 - val_loss: 0.0375 - val_acc: 0.9939\n",
      "Epoch 11/50\n",
      "1474/1474 [==============================] - 1s 493us/sample - loss: 5.5345e-04 - acc: 1.0000 - val_loss: 0.0372 - val_acc: 0.9939\n",
      "Epoch 12/50\n",
      "1474/1474 [==============================] - 1s 458us/sample - loss: 4.9725e-04 - acc: 1.0000 - val_loss: 0.0386 - val_acc: 0.9939\n",
      "Epoch 13/50\n",
      "1474/1474 [==============================] - 1s 479us/sample - loss: 4.4924e-04 - acc: 1.0000 - val_loss: 0.0377 - val_acc: 0.9939\n",
      "Epoch 14/50\n",
      "1474/1474 [==============================] - 1s 463us/sample - loss: 4.0947e-04 - acc: 1.0000 - val_loss: 0.0370 - val_acc: 0.9939\n",
      "Epoch 15/50\n",
      "1474/1474 [==============================] - 1s 470us/sample - loss: 3.7442e-04 - acc: 1.0000 - val_loss: 0.0364 - val_acc: 0.9939\n",
      "Epoch 16/50\n",
      "1474/1474 [==============================] - 1s 471us/sample - loss: 3.4677e-04 - acc: 1.0000 - val_loss: 0.0360 - val_acc: 0.9939\n",
      "Epoch 17/50\n",
      "1474/1474 [==============================] - 1s 456us/sample - loss: 3.1902e-04 - acc: 1.0000 - val_loss: 0.0358 - val_acc: 0.9939\n",
      "Epoch 18/50\n",
      "1474/1474 [==============================] - 1s 453us/sample - loss: 2.9767e-04 - acc: 1.0000 - val_loss: 0.0353 - val_acc: 0.9939\n",
      "Epoch 19/50\n",
      "1474/1474 [==============================] - 1s 476us/sample - loss: 2.7718e-04 - acc: 1.0000 - val_loss: 0.0349 - val_acc: 0.9939\n",
      "Epoch 20/50\n",
      "1474/1474 [==============================] - 1s 457us/sample - loss: 2.5930e-04 - acc: 1.0000 - val_loss: 0.0346 - val_acc: 0.9939\n",
      "Epoch 21/50\n",
      "1474/1474 [==============================] - 1s 456us/sample - loss: 2.4384e-04 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9939\n",
      "Epoch 22/50\n",
      "1474/1474 [==============================] - 1s 471us/sample - loss: 2.2969e-04 - acc: 1.0000 - val_loss: 0.0345 - val_acc: 0.9939\n",
      "Epoch 23/50\n",
      "1474/1474 [==============================] - 1s 459us/sample - loss: 2.1607e-04 - acc: 1.0000 - val_loss: 0.0338 - val_acc: 0.9878\n",
      "Epoch 24/50\n",
      "1474/1474 [==============================] - 1s 471us/sample - loss: 2.0427e-04 - acc: 1.0000 - val_loss: 0.0341 - val_acc: 0.9878\n",
      "Epoch 25/50\n",
      "1474/1474 [==============================] - 1s 456us/sample - loss: 1.9301e-04 - acc: 1.0000 - val_loss: 0.0341 - val_acc: 0.9878\n",
      "Epoch 26/50\n",
      "1474/1474 [==============================] - 1s 489us/sample - loss: 1.8315e-04 - acc: 1.0000 - val_loss: 0.0340 - val_acc: 0.9878\n",
      "Epoch 27/50\n",
      "1474/1474 [==============================] - 1s 516us/sample - loss: 1.7393e-04 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9878\n",
      "Epoch 28/50\n",
      "1474/1474 [==============================] - 1s 490us/sample - loss: 1.6532e-04 - acc: 1.0000 - val_loss: 0.0338 - val_acc: 0.9878\n",
      "Epoch 29/50\n",
      "1474/1474 [==============================] - 1s 482us/sample - loss: 1.5738e-04 - acc: 1.0000 - val_loss: 0.0339 - val_acc: 0.9878\n",
      "Epoch 30/50\n",
      "1474/1474 [==============================] - 1s 497us/sample - loss: 1.5086e-04 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9878\n",
      "Epoch 31/50\n",
      "1474/1474 [==============================] - 1s 513us/sample - loss: 1.4370e-04 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9878\n",
      "Epoch 32/50\n",
      "1474/1474 [==============================] - 1s 465us/sample - loss: 1.3636e-04 - acc: 1.0000 - val_loss: 0.0345 - val_acc: 0.9878\n",
      "Epoch 33/50\n",
      "1474/1474 [==============================] - 1s 480us/sample - loss: 1.3009e-04 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9878\n",
      "Epoch 34/50\n",
      "1474/1474 [==============================] - 1s 457us/sample - loss: 1.2462e-04 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9878\n",
      "Epoch 35/50\n",
      "1474/1474 [==============================] - 1s 449us/sample - loss: 1.1906e-04 - acc: 1.0000 - val_loss: 0.0344 - val_acc: 0.9878\n",
      "Epoch 36/50\n",
      "1474/1474 [==============================] - 1s 464us/sample - loss: 1.1395e-04 - acc: 1.0000 - val_loss: 0.0344 - val_acc: 0.9878\n",
      "Epoch 37/50\n",
      "1474/1474 [==============================] - 1s 466us/sample - loss: 1.0914e-04 - acc: 1.0000 - val_loss: 0.0344 - val_acc: 0.9878\n",
      "Epoch 38/50\n",
      "1474/1474 [==============================] - 1s 447us/sample - loss: 1.0446e-04 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9878\n",
      "Epoch 39/50\n",
      "1474/1474 [==============================] - 1s 461us/sample - loss: 1.0052e-04 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9878\n",
      "Epoch 40/50\n",
      "1474/1474 [==============================] - 1s 455us/sample - loss: 9.6463e-05 - acc: 1.0000 - val_loss: 0.0341 - val_acc: 0.9878\n",
      "Epoch 41/50\n",
      "1474/1474 [==============================] - 1s 450us/sample - loss: 9.2607e-05 - acc: 1.0000 - val_loss: 0.0342 - val_acc: 0.9878\n",
      "Epoch 42/50\n",
      "1474/1474 [==============================] - 1s 476us/sample - loss: 8.9161e-05 - acc: 1.0000 - val_loss: 0.0340 - val_acc: 0.9878\n",
      "Epoch 43/50\n",
      "1474/1474 [==============================] - 1s 495us/sample - loss: 8.5889e-05 - acc: 1.0000 - val_loss: 0.0341 - val_acc: 0.9878\n",
      "Epoch 44/50\n",
      "1474/1474 [==============================] - 1s 471us/sample - loss: 8.2715e-05 - acc: 1.0000 - val_loss: 0.0342 - val_acc: 0.9878\n",
      "Epoch 45/50\n",
      "1474/1474 [==============================] - 1s 469us/sample - loss: 7.9592e-05 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9878\n",
      "Epoch 46/50\n",
      "1474/1474 [==============================] - 1s 468us/sample - loss: 7.6704e-05 - acc: 1.0000 - val_loss: 0.0342 - val_acc: 0.9878\n",
      "Epoch 47/50\n",
      "1474/1474 [==============================] - 1s 484us/sample - loss: 7.4022e-05 - acc: 1.0000 - val_loss: 0.0346 - val_acc: 0.9878\n",
      "Epoch 48/50\n",
      "1474/1474 [==============================] - 1s 468us/sample - loss: 7.1506e-05 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 0.9878\n",
      "Epoch 49/50\n",
      "1474/1474 [==============================] - 1s 482us/sample - loss: 6.8849e-05 - acc: 1.0000 - val_loss: 0.0346 - val_acc: 0.9878\n",
      "Epoch 50/50\n",
      "1474/1474 [==============================] - 1s 487us/sample - loss: 6.6145e-05 - acc: 1.0000 - val_loss: 0.0347 - val_acc: 0.9878\n",
      "Train on 1474 samples, validate on 164 samples\n",
      "Epoch 1/50\n",
      "1474/1474 [==============================] - 1s 506us/sample - loss: 0.0913 - acc: 0.9742 - val_loss: 0.2749 - val_acc: 0.9329\n",
      "Epoch 2/50\n",
      "1474/1474 [==============================] - 1s 474us/sample - loss: 0.2858 - acc: 0.9138 - val_loss: 0.0777 - val_acc: 0.9756\n",
      "Epoch 3/50\n",
      "1474/1474 [==============================] - 1s 468us/sample - loss: 0.0631 - acc: 0.9796 - val_loss: 0.0289 - val_acc: 0.9939\n",
      "Epoch 4/50\n",
      "1474/1474 [==============================] - 1s 463us/sample - loss: 0.0166 - acc: 0.9959 - val_loss: 0.0295 - val_acc: 0.9878\n",
      "Epoch 5/50\n",
      "1474/1474 [==============================] - 1s 477us/sample - loss: 0.0095 - acc: 0.9973 - val_loss: 0.0212 - val_acc: 0.9939\n",
      "Epoch 6/50\n",
      "1474/1474 [==============================] - 1s 470us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0162 - val_acc: 0.9939\n",
      "Epoch 7/50\n",
      "1474/1474 [==============================] - 1s 474us/sample - loss: 9.8396e-04 - acc: 1.0000 - val_loss: 0.0138 - val_acc: 0.9939\n",
      "Epoch 8/50\n",
      "1474/1474 [==============================] - 1s 470us/sample - loss: 7.6322e-04 - acc: 1.0000 - val_loss: 0.0122 - val_acc: 1.0000\n",
      "Epoch 9/50\n",
      "1474/1474 [==============================] - 1s 474us/sample - loss: 6.4105e-04 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "Epoch 10/50\n",
      "1474/1474 [==============================] - 1s 483us/sample - loss: 5.5491e-04 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 1.0000\n",
      "Epoch 11/50\n",
      "1474/1474 [==============================] - 1s 464us/sample - loss: 4.9236e-04 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 12/50\n",
      "1474/1474 [==============================] - 1s 493us/sample - loss: 4.4362e-04 - acc: 1.0000 - val_loss: 0.0101 - val_acc: 1.0000\n",
      "Epoch 13/50\n",
      "1474/1474 [==============================] - 1s 456us/sample - loss: 3.9990e-04 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 1.0000\n",
      "Epoch 14/50\n",
      "1474/1474 [==============================] - 1s 470us/sample - loss: 3.6497e-04 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 1.0000\n",
      "Epoch 15/50\n",
      "1474/1474 [==============================] - 1s 463us/sample - loss: 3.3471e-04 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 1.0000\n",
      "Epoch 16/50\n",
      "1474/1474 [==============================] - 1s 460us/sample - loss: 3.0997e-04 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 1.0000\n",
      "Epoch 17/50\n",
      "1474/1474 [==============================] - 1s 462us/sample - loss: 2.8679e-04 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 1.0000\n",
      "Epoch 18/50\n",
      "1474/1474 [==============================] - 1s 464us/sample - loss: 2.6817e-04 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 1.0000\n",
      "Epoch 19/50\n",
      "1474/1474 [==============================] - 1s 480us/sample - loss: 2.5106e-04 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 1.0000\n",
      "Epoch 20/50\n",
      "1474/1474 [==============================] - 1s 467us/sample - loss: 2.3513e-04 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 1.0000\n",
      "Epoch 21/50\n",
      "1474/1474 [==============================] - 1s 466us/sample - loss: 2.2087e-04 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 1.0000\n",
      "Epoch 22/50\n",
      "1474/1474 [==============================] - 1s 445us/sample - loss: 2.0849e-04 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 1.0000\n",
      "Epoch 23/50\n",
      "1474/1474 [==============================] - 1s 479us/sample - loss: 1.9744e-04 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 1.0000\n",
      "Epoch 24/50\n",
      "1474/1474 [==============================] - 1s 461us/sample - loss: 1.8665e-04 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 25/50\n",
      "1474/1474 [==============================] - 1s 455us/sample - loss: 1.7687e-04 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 26/50\n",
      "1474/1474 [==============================] - 1s 470us/sample - loss: 1.6794e-04 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 27/50\n",
      "1474/1474 [==============================] - 1s 443us/sample - loss: 1.5999e-04 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 28/50\n",
      "1474/1474 [==============================] - 1s 480us/sample - loss: 1.5215e-04 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 1.0000\n",
      "Epoch 29/50\n",
      "1474/1474 [==============================] - 1s 464us/sample - loss: 1.4500e-04 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 1.0000\n",
      "Epoch 30/50\n",
      "1474/1474 [==============================] - 1s 457us/sample - loss: 1.3829e-04 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 1.0000\n",
      "Epoch 31/50\n",
      "1474/1474 [==============================] - 1s 460us/sample - loss: 1.3232e-04 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 1.0000\n",
      "Epoch 32/50\n",
      "1474/1474 [==============================] - 1s 469us/sample - loss: 1.2650e-04 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 33/50\n",
      "1474/1474 [==============================] - 1s 455us/sample - loss: 1.2121e-04 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
      "Epoch 34/50\n",
      "1474/1474 [==============================] - 1s 466us/sample - loss: 1.1631e-04 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 1.0000\n",
      "Epoch 35/50\n",
      "1474/1474 [==============================] - 1s 455us/sample - loss: 1.1092e-04 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 1.0000\n",
      "Epoch 36/50\n",
      "1474/1474 [==============================] - 1s 456us/sample - loss: 1.0648e-04 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "Epoch 37/50\n",
      "1474/1474 [==============================] - 1s 473us/sample - loss: 1.0217e-04 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
      "Epoch 38/50\n",
      "1474/1474 [==============================] - 1s 447us/sample - loss: 9.8062e-05 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "Epoch 39/50\n",
      "1474/1474 [==============================] - 1s 460us/sample - loss: 9.4409e-05 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "Epoch 40/50\n",
      "1474/1474 [==============================] - 1s 462us/sample - loss: 9.0756e-05 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 1.0000\n",
      "Epoch 41/50\n",
      "1474/1474 [==============================] - 1s 466us/sample - loss: 8.7376e-05 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 1.0000\n",
      "Epoch 42/50\n",
      "1474/1474 [==============================] - 1s 463us/sample - loss: 8.4144e-05 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 1.0000\n",
      "Epoch 43/50\n",
      "1474/1474 [==============================] - 1s 468us/sample - loss: 8.0914e-05 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 1.0000\n",
      "Epoch 44/50\n",
      "1474/1474 [==============================] - 1s 447us/sample - loss: 7.8038e-05 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1474/1474 [==============================] - 1s 462us/sample - loss: 7.5051e-05 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 1.0000\n",
      "Epoch 46/50\n",
      "1474/1474 [==============================] - 1s 475us/sample - loss: 7.2296e-05 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 1.0000\n",
      "Epoch 47/50\n",
      "1474/1474 [==============================] - 1s 453us/sample - loss: 6.9748e-05 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 1.0000\n",
      "Epoch 48/50\n",
      "1474/1474 [==============================] - 1s 463us/sample - loss: 6.7327e-05 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 1.0000\n",
      "Epoch 49/50\n",
      "1474/1474 [==============================] - 1s 448us/sample - loss: 6.5066e-05 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 1.0000\n",
      "Epoch 50/50\n",
      "1474/1474 [==============================] - 1s 478us/sample - loss: 6.2733e-05 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 1.0000\n",
      "Train on 1474 samples, validate on 164 samples\n",
      "Epoch 1/50\n",
      "1474/1474 [==============================] - 1s 464us/sample - loss: 0.0633 - acc: 0.9851 - val_loss: 0.0879 - val_acc: 0.9756\n",
      "Epoch 2/50\n",
      "1474/1474 [==============================] - 1s 471us/sample - loss: 0.1480 - acc: 0.9518 - val_loss: 0.2144 - val_acc: 0.9207\n",
      "Epoch 3/50\n",
      "1474/1474 [==============================] - 1s 451us/sample - loss: 0.0732 - acc: 0.9735 - val_loss: 0.0439 - val_acc: 0.9878\n",
      "Epoch 4/50\n",
      "1474/1474 [==============================] - 1s 459us/sample - loss: 0.0240 - acc: 0.9925 - val_loss: 0.0491 - val_acc: 0.9878\n",
      "Epoch 5/50\n",
      "1474/1474 [==============================] - 1s 470us/sample - loss: 0.0116 - acc: 0.9973 - val_loss: 0.0391 - val_acc: 0.9878\n",
      "Epoch 6/50\n",
      "1474/1474 [==============================] - 1s 457us/sample - loss: 0.0034 - acc: 0.9993 - val_loss: 0.0310 - val_acc: 0.9939\n",
      "Epoch 7/50\n",
      "1474/1474 [==============================] - 1s 461us/sample - loss: 8.1033e-04 - acc: 1.0000 - val_loss: 0.0251 - val_acc: 0.9939\n",
      "Epoch 8/50\n",
      "1474/1474 [==============================] - 1s 455us/sample - loss: 4.8180e-04 - acc: 1.0000 - val_loss: 0.0237 - val_acc: 0.9939\n",
      "Epoch 9/50\n",
      "1474/1474 [==============================] - 1s 472us/sample - loss: 3.9463e-04 - acc: 1.0000 - val_loss: 0.0235 - val_acc: 0.9939\n",
      "Epoch 10/50\n",
      "1474/1474 [==============================] - 1s 456us/sample - loss: 3.4361e-04 - acc: 1.0000 - val_loss: 0.0231 - val_acc: 0.9939\n",
      "Epoch 11/50\n",
      "1474/1474 [==============================] - 1s 459us/sample - loss: 3.0476e-04 - acc: 1.0000 - val_loss: 0.0228 - val_acc: 0.9939\n",
      "Epoch 12/50\n",
      "1474/1474 [==============================] - 1s 462us/sample - loss: 2.7526e-04 - acc: 1.0000 - val_loss: 0.0230 - val_acc: 0.9939\n",
      "Epoch 13/50\n",
      "1474/1474 [==============================] - 1s 453us/sample - loss: 2.5065e-04 - acc: 1.0000 - val_loss: 0.0225 - val_acc: 0.9939\n",
      "Epoch 14/50\n",
      "1474/1474 [==============================] - 1s 474us/sample - loss: 2.3018e-04 - acc: 1.0000 - val_loss: 0.0226 - val_acc: 0.9939\n",
      "Epoch 15/50\n",
      "1474/1474 [==============================] - ETA: 0s - loss: 2.1289e-04 - acc: 1.000 - 1s 462us/sample - loss: 2.1300e-04 - acc: 1.0000 - val_loss: 0.0229 - val_acc: 0.9939\n",
      "Epoch 16/50\n",
      "1474/1474 [==============================] - 1s 451us/sample - loss: 1.9821e-04 - acc: 1.0000 - val_loss: 0.0230 - val_acc: 0.9939\n",
      "Epoch 17/50\n",
      "1474/1474 [==============================] - 1s 464us/sample - loss: 1.8539e-04 - acc: 1.0000 - val_loss: 0.0229 - val_acc: 0.9939\n",
      "Epoch 18/50\n",
      "1474/1474 [==============================] - 1s 464us/sample - loss: 1.7348e-04 - acc: 1.0000 - val_loss: 0.0232 - val_acc: 0.9939\n",
      "Epoch 19/50\n",
      "1474/1474 [==============================] - 1s 465us/sample - loss: 1.6362e-04 - acc: 1.0000 - val_loss: 0.0232 - val_acc: 0.9939\n",
      "Epoch 20/50\n",
      "1474/1474 [==============================] - 1s 457us/sample - loss: 1.5424e-04 - acc: 1.0000 - val_loss: 0.0232 - val_acc: 0.9939\n",
      "Epoch 21/50\n",
      "1474/1474 [==============================] - 1s 457us/sample - loss: 1.4557e-04 - acc: 1.0000 - val_loss: 0.0232 - val_acc: 0.9939\n",
      "Epoch 22/50\n",
      "1474/1474 [==============================] - 1s 456us/sample - loss: 1.3783e-04 - acc: 1.0000 - val_loss: 0.0234 - val_acc: 0.9939\n",
      "Epoch 23/50\n",
      "1474/1474 [==============================] - 1s 478us/sample - loss: 1.3083e-04 - acc: 1.0000 - val_loss: 0.0234 - val_acc: 0.9939\n",
      "Epoch 24/50\n",
      "1474/1474 [==============================] - 1s 453us/sample - loss: 1.2441e-04 - acc: 1.0000 - val_loss: 0.0234 - val_acc: 0.9939\n",
      "Epoch 25/50\n",
      "1474/1474 [==============================] - 1s 457us/sample - loss: 1.1837e-04 - acc: 1.0000 - val_loss: 0.0235 - val_acc: 0.9939\n",
      "Epoch 26/50\n",
      "1474/1474 [==============================] - 1s 461us/sample - loss: 1.1263e-04 - acc: 1.0000 - val_loss: 0.0236 - val_acc: 0.9939\n",
      "Epoch 27/50\n",
      "1474/1474 [==============================] - 1s 462us/sample - loss: 1.0679e-04 - acc: 1.0000 - val_loss: 0.0233 - val_acc: 0.9939\n",
      "Epoch 28/50\n",
      "1474/1474 [==============================] - 1s 468us/sample - loss: 1.0204e-04 - acc: 1.0000 - val_loss: 0.0235 - val_acc: 0.9939\n",
      "Epoch 29/50\n",
      "1474/1474 [==============================] - 1s 467us/sample - loss: 9.7538e-05 - acc: 1.0000 - val_loss: 0.0237 - val_acc: 0.9939\n",
      "Epoch 30/50\n",
      "1474/1474 [==============================] - 1s 455us/sample - loss: 9.3345e-05 - acc: 1.0000 - val_loss: 0.0237 - val_acc: 0.9939\n",
      "Epoch 31/50\n",
      "1474/1474 [==============================] - 1s 457us/sample - loss: 8.9270e-05 - acc: 1.0000 - val_loss: 0.0234 - val_acc: 0.9939\n",
      "Epoch 32/50\n",
      "1474/1474 [==============================] - 1s 475us/sample - loss: 8.5580e-05 - acc: 1.0000 - val_loss: 0.0236 - val_acc: 0.9939\n",
      "Epoch 33/50\n",
      "1474/1474 [==============================] - 1s 449us/sample - loss: 8.2070e-05 - acc: 1.0000 - val_loss: 0.0241 - val_acc: 0.9939\n",
      "Epoch 34/50\n",
      "1474/1474 [==============================] - 1s 465us/sample - loss: 7.8649e-05 - acc: 1.0000 - val_loss: 0.0242 - val_acc: 0.9939\n",
      "Epoch 35/50\n",
      "1474/1474 [==============================] - 1s 457us/sample - loss: 7.5620e-05 - acc: 1.0000 - val_loss: 0.0243 - val_acc: 0.9939\n",
      "Epoch 36/50\n",
      "1474/1474 [==============================] - 1s 467us/sample - loss: 7.2592e-05 - acc: 1.0000 - val_loss: 0.0243 - val_acc: 0.9939\n",
      "Epoch 37/50\n",
      "1474/1474 [==============================] - 1s 472us/sample - loss: 6.9902e-05 - acc: 1.0000 - val_loss: 0.0244 - val_acc: 0.9939\n",
      "Epoch 38/50\n",
      "1474/1474 [==============================] - 1s 452us/sample - loss: 6.7288e-05 - acc: 1.0000 - val_loss: 0.0246 - val_acc: 0.9939\n",
      "Epoch 39/50\n",
      "1474/1474 [==============================] - 1s 459us/sample - loss: 6.4800e-05 - acc: 1.0000 - val_loss: 0.0248 - val_acc: 0.9939\n",
      "Epoch 40/50\n",
      "1474/1474 [==============================] - 1s 457us/sample - loss: 6.2413e-05 - acc: 1.0000 - val_loss: 0.0249 - val_acc: 0.9939\n",
      "Epoch 41/50\n",
      "1474/1474 [==============================] - 1s 472us/sample - loss: 6.0126e-05 - acc: 1.0000 - val_loss: 0.0249 - val_acc: 0.9939\n",
      "Epoch 42/50\n",
      "1474/1474 [==============================] - 1s 463us/sample - loss: 5.8017e-05 - acc: 1.0000 - val_loss: 0.0249 - val_acc: 0.9939\n",
      "Epoch 43/50\n",
      "1474/1474 [==============================] - 1s 458us/sample - loss: 5.6072e-05 - acc: 1.0000 - val_loss: 0.0250 - val_acc: 0.9939\n",
      "Epoch 44/50\n",
      "1474/1474 [==============================] - 1s 462us/sample - loss: 5.4182e-05 - acc: 1.0000 - val_loss: 0.0250 - val_acc: 0.9939\n",
      "Epoch 45/50\n",
      "1474/1474 [==============================] - 1s 472us/sample - loss: 5.2251e-05 - acc: 1.0000 - val_loss: 0.0250 - val_acc: 0.9939\n",
      "Epoch 46/50\n",
      "1474/1474 [==============================] - 1s 484us/sample - loss: 5.0511e-05 - acc: 1.0000 - val_loss: 0.0250 - val_acc: 0.9939\n",
      "Epoch 47/50\n",
      "1474/1474 [==============================] - ETA: 0s - loss: 4.8589e-05 - acc: 1.000 - 1s 470us/sample - loss: 4.8796e-05 - acc: 1.0000 - val_loss: 0.0252 - val_acc: 0.9939\n",
      "Epoch 48/50\n",
      "1474/1474 [==============================] - 1s 470us/sample - loss: 4.7211e-05 - acc: 1.0000 - val_loss: 0.0252 - val_acc: 0.9939\n",
      "Epoch 49/50\n",
      "1474/1474 [==============================] - 1s 465us/sample - loss: 4.5649e-05 - acc: 1.0000 - val_loss: 0.0256 - val_acc: 0.9939\n",
      "Epoch 50/50\n",
      "1474/1474 [==============================] - 1s 477us/sample - loss: 4.4219e-05 - acc: 1.0000 - val_loss: 0.0257 - val_acc: 0.9939\n",
      "Train on 1475 samples, validate on 163 samples\n",
      "Epoch 1/50\n",
      "1475/1475 [==============================] - 1s 469us/sample - loss: 0.0271 - acc: 0.9885 - val_loss: 0.1009 - val_acc: 0.9693\n",
      "Epoch 2/50\n",
      "1475/1475 [==============================] - 1s 469us/sample - loss: 0.1242 - acc: 0.9614 - val_loss: 0.2353 - val_acc: 0.9387\n",
      "Epoch 3/50\n",
      "1475/1475 [==============================] - 1s 477us/sample - loss: 0.1204 - acc: 0.9600 - val_loss: 0.1585 - val_acc: 0.9509\n",
      "Epoch 4/50\n",
      "1475/1475 [==============================] - 1s 483us/sample - loss: 0.0192 - acc: 0.9939 - val_loss: 0.0116 - val_acc: 1.0000\n",
      "Epoch 5/50\n",
      "1475/1475 [==============================] - 1s 477us/sample - loss: 0.0032 - acc: 0.9993 - val_loss: 0.0075 - val_acc: 1.0000\n",
      "Epoch 6/50\n",
      "1475/1475 [==============================] - 1s 477us/sample - loss: 7.2740e-04 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 7/50\n",
      "1475/1475 [==============================] - 1s 473us/sample - loss: 4.7641e-04 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 8/50\n",
      "1475/1475 [==============================] - 1s 468us/sample - loss: 3.9355e-04 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 9/50\n",
      "1475/1475 [==============================] - 1s 496us/sample - loss: 3.3899e-04 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 10/50\n",
      "1475/1475 [==============================] - 1s 481us/sample - loss: 2.9987e-04 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 11/50\n",
      "1475/1475 [==============================] - 1s 471us/sample - loss: 2.6678e-04 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 12/50\n",
      "1475/1475 [==============================] - 1s 477us/sample - loss: 2.4185e-04 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 13/50\n",
      "1475/1475 [==============================] - 1s 483us/sample - loss: 2.2133e-04 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 14/50\n",
      "1475/1475 [==============================] - 1s 471us/sample - loss: 2.0332e-04 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 15/50\n",
      "1475/1475 [==============================] - 1s 473us/sample - loss: 1.8859e-04 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 16/50\n",
      "1475/1475 [==============================] - 1s 479us/sample - loss: 1.7510e-04 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 17/50\n",
      "1475/1475 [==============================] - 1s 472us/sample - loss: 1.6346e-04 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 18/50\n",
      "1475/1475 [==============================] - 1s 476us/sample - loss: 1.5294e-04 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 19/50\n",
      "1475/1475 [==============================] - 1s 475us/sample - loss: 1.4341e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 20/50\n",
      "1475/1475 [==============================] - 1s 469us/sample - loss: 1.3518e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 21/50\n",
      "1475/1475 [==============================] - 1s 490us/sample - loss: 1.2767e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 22/50\n",
      "1475/1475 [==============================] - 1s 483us/sample - loss: 1.2099e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 23/50\n",
      "1475/1475 [==============================] - 1s 471us/sample - loss: 1.1460e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 24/50\n",
      "1475/1475 [==============================] - 1s 469us/sample - loss: 1.0888e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 25/50\n",
      "1475/1475 [==============================] - 1s 475us/sample - loss: 1.0339e-04 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 26/50\n",
      "1475/1475 [==============================] - 1s 479us/sample - loss: 9.8486e-05 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 27/50\n",
      "1475/1475 [==============================] - 1s 469us/sample - loss: 9.4192e-05 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000 loss: 9.4301e-05 - acc: 1.000\n",
      "Epoch 28/50\n",
      "1475/1475 [==============================] - 1s 477us/sample - loss: 8.9809e-05 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 29/50\n",
      "1475/1475 [==============================] - 1s 475us/sample - loss: 8.5725e-05 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 30/50\n",
      "1475/1475 [==============================] - 1s 481us/sample - loss: 8.2118e-05 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 31/50\n",
      "1475/1475 [==============================] - 1s 483us/sample - loss: 7.8758e-05 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 32/50\n",
      "1475/1475 [==============================] - 1s 469us/sample - loss: 7.5491e-05 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 33/50\n",
      "1475/1475 [==============================] - 1s 473us/sample - loss: 7.2579e-05 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 34/50\n",
      "1475/1475 [==============================] - 1s 474us/sample - loss: 6.9792e-05 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 35/50\n",
      "1475/1475 [==============================] - 1s 477us/sample - loss: 6.7183e-05 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 36/50\n",
      "1475/1475 [==============================] - 1s 471us/sample - loss: 6.4482e-05 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 37/50\n",
      "1475/1475 [==============================] - 1s 529us/sample - loss: 6.1999e-05 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 38/50\n",
      "1475/1475 [==============================] - 1s 557us/sample - loss: 5.9779e-05 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 39/50\n",
      "1475/1475 [==============================] - 1s 542us/sample - loss: 5.7864e-05 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 40/50\n",
      "1475/1475 [==============================] - 1s 531us/sample - loss: 5.5696e-05 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 41/50\n",
      "1475/1475 [==============================] - 1s 498us/sample - loss: 5.3663e-05 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 42/50\n",
      "1475/1475 [==============================] - 1s 474us/sample - loss: 5.1829e-05 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 43/50\n",
      "1475/1475 [==============================] - 1s 475us/sample - loss: 5.0105e-05 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 44/50\n",
      "1475/1475 [==============================] - 1s 469us/sample - loss: 4.8273e-05 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 45/50\n",
      "1475/1475 [==============================] - 1s 489us/sample - loss: 4.6696e-05 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 46/50\n",
      "1475/1475 [==============================] - 1s 477us/sample - loss: 4.5138e-05 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 47/50\n",
      "1475/1475 [==============================] - 1s 464us/sample - loss: 4.3708e-05 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 48/50\n",
      "1475/1475 [==============================] - 1s 484us/sample - loss: 4.2289e-05 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 49/50\n",
      "1475/1475 [==============================] - 1s 472us/sample - loss: 4.0905e-05 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 50/50\n",
      "1475/1475 [==============================] - 1s 475us/sample - loss: 3.9655e-05 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Train on 1475 samples, validate on 163 samples\n",
      "Epoch 1/50\n",
      "1475/1475 [==============================] - 1s 478us/sample - loss: 2.9260e-04 - acc: 1.0000 - val_loss: 4.1699e-05 - val_acc: 1.0000\n",
      "Epoch 2/50\n",
      "1475/1475 [==============================] - 1s 481us/sample - loss: 8.9669e-05 - acc: 1.0000 - val_loss: 3.9321e-05 - val_acc: 1.0000\n",
      "Epoch 3/50\n",
      "1475/1475 [==============================] - 1s 467us/sample - loss: 6.3988e-05 - acc: 1.0000 - val_loss: 3.6077e-05 - val_acc: 1.0000\n",
      "Epoch 4/50\n",
      "1475/1475 [==============================] - 1s 477us/sample - loss: 5.5395e-05 - acc: 1.0000 - val_loss: 3.4281e-05 - val_acc: 1.0000\n",
      "Epoch 5/50\n",
      "1475/1475 [==============================] - 1s 469us/sample - loss: 5.0407e-05 - acc: 1.0000 - val_loss: 3.2952e-05 - val_acc: 1.0000\n",
      "Epoch 6/50\n",
      "1475/1475 [==============================] - 1s 468us/sample - loss: 4.6540e-05 - acc: 1.0000 - val_loss: 3.1914e-05 - val_acc: 1.0000\n",
      "Epoch 7/50\n",
      "1475/1475 [==============================] - 1s 487us/sample - loss: 4.3613e-05 - acc: 1.0000 - val_loss: 3.1212e-05 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "1475/1475 [==============================] - 1s 477us/sample - loss: 4.1080e-05 - acc: 1.0000 - val_loss: 3.0427e-05 - val_acc: 1.0000\n",
      "Epoch 9/50\n",
      "1475/1475 [==============================] - 1s 470us/sample - loss: 3.8921e-05 - acc: 1.0000 - val_loss: 2.9730e-05 - val_acc: 1.0000\n",
      "Epoch 10/50\n",
      "1475/1475 [==============================] - 1s 485us/sample - loss: 3.7028e-05 - acc: 1.0000 - val_loss: 2.9205e-05 - val_acc: 1.0000\n",
      "Epoch 11/50\n",
      "1475/1475 [==============================] - 1s 485us/sample - loss: 3.5314e-05 - acc: 1.0000 - val_loss: 2.8537e-05 - val_acc: 1.0000\n",
      "Epoch 12/50\n",
      "1475/1475 [==============================] - 1s 464us/sample - loss: 3.3715e-05 - acc: 1.0000 - val_loss: 2.8024e-05 - val_acc: 1.0000\n",
      "Epoch 13/50\n",
      "1475/1475 [==============================] - 1s 464us/sample - loss: 3.2259e-05 - acc: 1.0000 - val_loss: 2.7386e-05 - val_acc: 1.0000\n",
      "Epoch 14/50\n",
      "1475/1475 [==============================] - 1s 478us/sample - loss: 3.0920e-05 - acc: 1.0000 - val_loss: 2.6971e-05 - val_acc: 1.0000\n",
      "Epoch 15/50\n",
      "1475/1475 [==============================] - 1s 474us/sample - loss: 2.9698e-05 - acc: 1.0000 - val_loss: 2.6477e-05 - val_acc: 1.0000\n",
      "Epoch 16/50\n",
      "1475/1475 [==============================] - 1s 476us/sample - loss: 2.8565e-05 - acc: 1.0000 - val_loss: 2.6012e-05 - val_acc: 1.0000\n",
      "Epoch 17/50\n",
      "1475/1475 [==============================] - 1s 477us/sample - loss: 2.7514e-05 - acc: 1.0000 - val_loss: 2.5628e-05 - val_acc: 1.0000\n",
      "Epoch 18/50\n",
      "1475/1475 [==============================] - 1s 473us/sample - loss: 2.6518e-05 - acc: 1.0000 - val_loss: 2.5271e-05 - val_acc: 1.0000\n",
      "Epoch 19/50\n",
      "1475/1475 [==============================] - 1s 474us/sample - loss: 2.5558e-05 - acc: 1.0000 - val_loss: 2.4851e-05 - val_acc: 1.0000\n",
      "Epoch 20/50\n",
      "1475/1475 [==============================] - 1s 483us/sample - loss: 2.4673e-05 - acc: 1.0000 - val_loss: 2.4579e-05 - val_acc: 1.0000\n",
      "Epoch 21/50\n",
      "1475/1475 [==============================] - 1s 484us/sample - loss: 2.3843e-05 - acc: 1.0000 - val_loss: 2.4138e-05 - val_acc: 1.0000\n",
      "Epoch 22/50\n",
      "1475/1475 [==============================] - 1s 473us/sample - loss: 2.3015e-05 - acc: 1.0000 - val_loss: 2.3786e-05 - val_acc: 1.0000\n",
      "Epoch 23/50\n",
      "1475/1475 [==============================] - 1s 475us/sample - loss: 2.2241e-05 - acc: 1.0000 - val_loss: 2.3457e-05 - val_acc: 1.0000\n",
      "Epoch 24/50\n",
      "1475/1475 [==============================] - 1s 488us/sample - loss: 2.1503e-05 - acc: 1.0000 - val_loss: 2.3084e-05 - val_acc: 1.0000\n",
      "Epoch 25/50\n",
      "1475/1475 [==============================] - 1s 481us/sample - loss: 2.0783e-05 - acc: 1.0000 - val_loss: 2.2810e-05 - val_acc: 1.0000\n",
      "Epoch 26/50\n",
      "1475/1475 [==============================] - 1s 469us/sample - loss: 2.0114e-05 - acc: 1.0000 - val_loss: 2.2573e-05 - val_acc: 1.0000\n",
      "Epoch 27/50\n",
      "1475/1475 [==============================] - 1s 477us/sample - loss: 1.9501e-05 - acc: 1.0000 - val_loss: 2.2278e-05 - val_acc: 1.0000\n",
      "Epoch 28/50\n",
      "1475/1475 [==============================] - 1s 503us/sample - loss: 1.8859e-05 - acc: 1.0000 - val_loss: 2.1934e-05 - val_acc: 1.0000\n",
      "Epoch 29/50\n",
      "1475/1475 [==============================] - 1s 481us/sample - loss: 1.8268e-05 - acc: 1.0000 - val_loss: 2.1595e-05 - val_acc: 1.0000\n",
      "Epoch 30/50\n",
      "1475/1475 [==============================] - 1s 503us/sample - loss: 1.7694e-05 - acc: 1.0000 - val_loss: 2.1386e-05 - val_acc: 1.0000\n",
      "Epoch 31/50\n",
      "1475/1475 [==============================] - 1s 495us/sample - loss: 1.7164e-05 - acc: 1.0000 - val_loss: 2.1142e-05 - val_acc: 1.0000\n",
      "Epoch 32/50\n",
      "1475/1475 [==============================] - 1s 502us/sample - loss: 1.6657e-05 - acc: 1.0000 - val_loss: 2.0817e-05 - val_acc: 1.0000\n",
      "Epoch 33/50\n",
      "1475/1475 [==============================] - 1s 523us/sample - loss: 1.6151e-05 - acc: 1.0000 - val_loss: 2.0575e-05 - val_acc: 1.0000\n",
      "Epoch 34/50\n",
      "1475/1475 [==============================] - 1s 514us/sample - loss: 1.5670e-05 - acc: 1.0000 - val_loss: 2.0405e-05 - val_acc: 1.0000\n",
      "Epoch 35/50\n",
      "1475/1475 [==============================] - 1s 497us/sample - loss: 1.5213e-05 - acc: 1.0000 - val_loss: 2.0151e-05 - val_acc: 1.0000\n",
      "Epoch 36/50\n",
      "1475/1475 [==============================] - 1s 482us/sample - loss: 1.4773e-05 - acc: 1.0000 - val_loss: 1.9889e-05 - val_acc: 1.0000\n",
      "Epoch 37/50\n",
      "1475/1475 [==============================] - 1s 504us/sample - loss: 1.4347e-05 - acc: 1.0000 - val_loss: 1.9725e-05 - val_acc: 1.0000\n",
      "Epoch 38/50\n",
      "1475/1475 [==============================] - 1s 486us/sample - loss: 1.3932e-05 - acc: 1.0000 - val_loss: 1.9458e-05 - val_acc: 1.0000\n",
      "Epoch 39/50\n",
      "1475/1475 [==============================] - 1s 495us/sample - loss: 1.3534e-05 - acc: 1.0000 - val_loss: 1.9233e-05 - val_acc: 1.0000\n",
      "Epoch 40/50\n",
      "1475/1475 [==============================] - 1s 510us/sample - loss: 1.3154e-05 - acc: 1.0000 - val_loss: 1.8985e-05 - val_acc: 1.0000\n",
      "Epoch 41/50\n",
      "1475/1475 [==============================] - 1s 513us/sample - loss: 1.2765e-05 - acc: 1.0000 - val_loss: 1.8886e-05 - val_acc: 1.0000\n",
      "Epoch 42/50\n",
      "1475/1475 [==============================] - 1s 496us/sample - loss: 1.2426e-05 - acc: 1.0000 - val_loss: 1.8718e-05 - val_acc: 1.0000\n",
      "Epoch 43/50\n",
      "1475/1475 [==============================] - 1s 505us/sample - loss: 1.2083e-05 - acc: 1.0000 - val_loss: 1.8530e-05 - val_acc: 1.0000\n",
      "Epoch 44/50\n",
      "1475/1475 [==============================] - 1s 493us/sample - loss: 1.1759e-05 - acc: 1.0000 - val_loss: 1.8243e-05 - val_acc: 1.0000\n",
      "Epoch 45/50\n",
      "1475/1475 [==============================] - 1s 504us/sample - loss: 1.1408e-05 - acc: 1.0000 - val_loss: 1.8064e-05 - val_acc: 1.0000\n",
      "Epoch 46/50\n",
      "1475/1475 [==============================] - 1s 493us/sample - loss: 1.1103e-05 - acc: 1.0000 - val_loss: 1.7888e-05 - val_acc: 1.0000\n",
      "Epoch 47/50\n",
      "1475/1475 [==============================] - 1s 488us/sample - loss: 1.0782e-05 - acc: 1.0000 - val_loss: 1.7752e-05 - val_acc: 1.0000\n",
      "Epoch 48/50\n",
      "1475/1475 [==============================] - 1s 484us/sample - loss: 1.0493e-05 - acc: 1.0000 - val_loss: 1.7569e-05 - val_acc: 1.0000\n",
      "Epoch 49/50\n",
      "1475/1475 [==============================] - 1s 498us/sample - loss: 1.0198e-05 - acc: 1.0000 - val_loss: 1.7303e-05 - val_acc: 1.0000\n",
      "Epoch 50/50\n",
      "1475/1475 [==============================] - 1s 512us/sample - loss: 9.9277e-06 - acc: 1.0000 - val_loss: 1.7115e-05 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 이건 kfold 코든데 한번 해바바!!\n",
    "# 내가 뭘잘못했을까ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ\n",
    "\n",
    "epochs = 50\n",
    "'''\n",
    "# Train-Test를 9:1로 분리\n",
    "X_train2, X_val2, y_train2, y_val2 = train_test_split(\n",
    "    x_train, y_train, test_size = 0.2)\n",
    "'''\n",
    "\n",
    "history = []\n",
    "\n",
    "#교차검증 수행\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train, validation in k_fold.split(x_train, y_train):\n",
    "    #fit 메서드로 트레이닝 시작\n",
    "    hist = model.fit(\n",
    "        x_train[train], y_train[train],\n",
    "        epochs=epochs,\n",
    "        validation_data=(x_train[validation], y_train[validation]),  \n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    history.append(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_val, y_val, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.436415672302246, 0.997560977935791]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
